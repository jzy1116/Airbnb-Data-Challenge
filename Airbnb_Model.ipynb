{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Airbnb Model.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89lNdo2G2iAY",
        "colab_type": "text"
      },
      "source": [
        "# Load Data and Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJoJOtpd-y8x",
        "colab_type": "code",
        "outputId": "7d14551a-98ec-4278-9075-c2e7d6eadeab",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e22ab8c6-4ef4-47db-bb0a-dd4aeb378e4b\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-e22ab8c6-4ef4-47db-bb0a-dd4aeb378e4b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving airbnb_model.csv to airbnb_model.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6v8XmXC2p4s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "9d14ae7a-62ed-4d6d-862e-f02f5334ff1e"
      },
      "source": [
        "# load packages\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import scipy\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.formula.api as sm\n",
        "import seaborn as sns\n",
        "import sklearn as sl\n",
        "from sklearn import preprocessing\n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UGC1uwC_HTp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "df = pd.read_csv(io.BytesIO(uploaded['airbnb_model.csv']), index_col=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9Cbr7XeS9FS",
        "colab_type": "code",
        "outputId": "3e51394f-1a20-4106-d5ed-855f2be7e57a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "df.info()\n",
        "#df.describe(percentiles = [.1, .25, .5, .75, .95])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 26393 entries, 0 to 26392\n",
            "Data columns (total 14 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   Unnamed: 0          26393 non-null  int64  \n",
            " 1   guest_size          26392 non-null  float64\n",
            " 2   total_interactions  26393 non-null  int64  \n",
            " 3   message_length      26393 non-null  float64\n",
            " 4   channel             26393 non-null  object \n",
            " 5   user_stage          26393 non-null  object \n",
            " 6   total_reviews       26309 non-null  float64\n",
            " 7   lead_time           26393 non-null  int64  \n",
            " 8   days_of_stay        26393 non-null  int64  \n",
            " 9   reply_t             14319 non-null  float64\n",
            " 10  accept_t            15247 non-null  float64\n",
            " 11  replied             26393 non-null  int64  \n",
            " 12  accepted            26393 non-null  int64  \n",
            " 13  booked              26393 non-null  int64  \n",
            "dtypes: float64(5), int64(7), object(2)\n",
            "memory usage: 2.8+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTuYZOe04RCP",
        "colab_type": "text"
      },
      "source": [
        "# Feature Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQQolleD4z5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop useless column\n",
        "df = df.drop(columns=['Unnamed: 0'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P3dW0ICuUzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# df.to_csv('airbnb_model.csv')\n",
        "# files.download('airbnb_model.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fheSKWzz3nEY",
        "colab_type": "text"
      },
      "source": [
        "## Filling missing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjZ2Be1b6U90",
        "colab_type": "text"
      },
      "source": [
        "Guest size, total_reviews have nulls.\n",
        "\n",
        "Deal with nulls in reply_t and accept_t later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qN7I06EN7HQI",
        "colab": {}
      },
      "source": [
        "# Replace guest size, total review with median \n",
        "df['total_reviews'].fillna(df['total_reviews'].median(), inplace=True)\n",
        "df['guest_size'].fillna(df['guest_size'].median(), inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAwZJ5_DM6EI",
        "colab_type": "text"
      },
      "source": [
        "## Feature encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtoPLUl6T8u8",
        "colab_type": "text"
      },
      "source": [
        "In order to see the nuances of some features' impact, I decided to create buckets for numerical variables including:\n",
        "*   Interaction\n",
        "*   Review\n",
        "*   Lead time\n",
        "*   Days of stay\n",
        "*   Message length\n",
        "*   Guest size\n",
        "\n",
        "\n",
        "\n",
        "And these bins will be used to create interactive features as well\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4r-z49HGfL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Binning the numerical features first\n",
        "\n",
        "# Binning interactions\n",
        "interaction = [0,10,20,30,1000]\n",
        "interaction_range = ['1-10','11-20','21-30','>30']\n",
        "interactions_bin = pd.cut(df['total_interactions'], bins = interaction, labels= interaction_range)\n",
        "df['interactions'] = interactions_bin\n",
        "\n",
        "# Binning reviews\n",
        "review = [-1,0,10,20,30,1000]\n",
        "review_range = ['0','1-10','11-20','21-30','>30']\n",
        "reviews_bin = pd.cut(df['total_reviews'], bins = review, labels=review_range)\n",
        "df['reviews'] = reviews_bin\n",
        "\n",
        "# Binning lead time\n",
        "lead = [-1,30,60,90,1000]\n",
        "lead_range = ['1-30d','31-60d','61-90d', '>90d']\n",
        "lead_bin = pd.cut(df['lead_time'], bins = lead, labels=lead_range)\n",
        "df['lead_time_bin'] = lead_bin\n",
        "\n",
        "# Binning days_of_stay\n",
        "stay = [-1,5,10,15,1000]\n",
        "stay_range = ['1-5d','6-10d','11-15d','>15d']\n",
        "stay_bin = pd.cut(df['days_of_stay'], bins = stay, labels=stay_range)\n",
        "df['days_of_stay_bin'] = stay_bin\n",
        "\n",
        "# Binning message_length\n",
        "length = [-1,150,300,450,3000]\n",
        "length_range = ['0-150','151-300','301-450','>450']\n",
        "length_bin = pd.cut(df['message_length'], bins = length, labels=length_range)\n",
        "df['message_length_bin'] = length_bin\n",
        "\n",
        "# Binning guest size\n",
        "size = [-1,1,2,4,6,30]\n",
        "size_range = ['1','2','3-4','5-6','>6']\n",
        "size_bin = pd.cut(df['guest_size'], bins = size, labels=size_range)\n",
        "df['guest_size_bin'] = size_bin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSjGWDt9MZxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One-hot-encoding each bin\n",
        "\n",
        "# Interactions\n",
        "df['1-10_interactions'] = np.where(df['interactions'] == '1-10', 1, 0)\n",
        "df['11-20_interactions'] = np.where(df['interactions'] == '11-20', 1, 0)\n",
        "df['21-30_interactions'] = np.where(df['interactions'] == '21-30', 1, 0)\n",
        "df['>30_interactions'] = np.where(df['interactions'] == '>30', 1, 0)\n",
        "\n",
        "# Reviews\n",
        "df['0_reviews'] = np.where(df['reviews'] == '0', 1, 0)\n",
        "df['1-10_reviews'] = np.where(df['reviews'] == '1-10', 1, 0)\n",
        "df['11-20_reviews'] = np.where(df['reviews'] == '11-20', 1, 0)\n",
        "df['21-30_reviews'] = np.where(df['reviews'] == '21-30', 1, 0)\n",
        "df['>30_reviews'] = np.where(df['reviews'] == '>30', 1, 0)\n",
        "\n",
        "# Lead time\n",
        "df['1-30d_lead_time'] = np.where(df['lead_time_bin'] == '1-30d', 1, 0)\n",
        "df['31-60d_lead_time'] = np.where(df['lead_time_bin'] == '31-60d', 1, 0)\n",
        "df['61-90d_lead_time'] = np.where(df['lead_time_bin'] == '61-90d', 1, 0)\n",
        "df['>90d_lead_time'] = np.where(df['lead_time_bin'] == '>90d', 1, 0)\n",
        "\n",
        "# Days of stay\n",
        "df['1-5d_stay'] = np.where(df['days_of_stay_bin'] == '1-5d', 1, 0)\n",
        "df['6-10d_stay'] = np.where(df['days_of_stay_bin'] == '6-10d', 1, 0)\n",
        "df['11-15d_stay'] = np.where(df['days_of_stay_bin'] == '11-15d', 1, 0)\n",
        "df['>15d_stay'] = np.where(df['days_of_stay_bin'] == '>15d', 1, 0)\n",
        "\n",
        "# Message length\n",
        "df['0-150_char_message'] = np.where(df['message_length_bin'] == '0-150', 1, 0)\n",
        "df['151-300_char_message'] = np.where(df['message_length_bin'] == '151-300', 1, 0)\n",
        "df['301-450_char_message'] = np.where(df['message_length_bin'] == '301-450', 1, 0)\n",
        "df['>450_char_message'] = np.where(df['message_length_bin'] == '>450', 1, 0)\n",
        "\n",
        "# Guest size\n",
        "size = [-1,1,2,4,6,30]\n",
        "size_range = ['1','2','3-4','5-6','>6']\n",
        "df['1_guest'] = np.where(df['guest_size_bin'] == '1', 1, 0)\n",
        "df['2_guests'] = np.where(df['guest_size_bin'] == '2', 1, 0)\n",
        "df['3-4_guests'] = np.where(df['guest_size_bin'] == '3-4', 1, 0)\n",
        "df['5-6_guests'] = np.where(df['guest_size_bin'] == '5-6', 1, 0)\n",
        "df['>6_guests'] = np.where(df['guest_size_bin'] == '>6', 1, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qz5hNk-Xa1E6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Categorical features \n",
        "df['contact_me'] = np.where(df['channel'] == 'contact_me', 1, 0)\n",
        "df['past_booker'] = np.where(df['user_stage'] == 'past_booker', 1, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxJLxBIQswOz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop original numerical/categorical features \n",
        "df = df.drop(columns=['total_interactions', 'total_reviews', 'lead_time', 'days_of_stay', 'message_length', 'guest_size', 'interactions', 'reviews', 'lead_time_bin',\t'days_of_stay_bin',\t'message_length_bin', 'guest_size_bin', 'user_stage'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B54El9-IuaTD",
        "colab_type": "text"
      },
      "source": [
        "## Interactive features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOTDUvPDuevL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interactions = ['1-10_interactions', '11-20_interactions', '21-30_interactions', '>30_interactions']\n",
        "reviews = ['0_reviews', '1-10_reviews', '11-20_reviews', '21-30_reviews', '>30_reviews']\n",
        "lead_times = ['1-30d_lead_time', '31-60d_lead_time', '61-90d_lead_time', '>90d_lead_time']\n",
        "stays = ['1-5d_stay', '6-10d_stay', '11-15d_stay', '>15d_stay']\n",
        "message_lengths = ['0-150_char_message', '151-300_char_message', '301-450_char_message', '>450_char_message']\n",
        "guest_sizes = ['1_guest', '2_guests', '3-4_guests', '5-6_guests', '>6_guests']\n",
        "\n",
        "# Interaction * message length\n",
        "for i in interactions:\n",
        "  for j in message_lengths:\n",
        "    df[i+'*'+j] = df[i] * df[j]\n",
        "\n",
        "# Interaction * lead time\n",
        "for i in interactions:\n",
        "  for j in lead_times:\n",
        "    df[i+'*'+j] = df[i] * df[j]\n",
        "\n",
        "# Interaction * days of stay\n",
        "for i in interactions:\n",
        "  for j in stays:\n",
        "    df[i+'*'+j] = df[i] * df[j]\n",
        "\n",
        "# User stage + interactions\n",
        "for i in interactions:\n",
        "    df['past_booker'+'*'+i] = df['past_booker'] * df[i]\n",
        "\n",
        "# Channel * user stage\n",
        "df['contact_me*past_booker'] = df['contact_me'] * df['past_booker']\n",
        "\n",
        "# Channel * lead_time\n",
        "for i in lead_times:\n",
        "  df['contact_me'+'*'+i] = df['contact_me'] * df[i]\n",
        "\n",
        "# Channel * guest size\n",
        "for i in guest_sizes:\n",
        "  df['contact_me'+'*'+i] = df['contact_me'] * df[i]\n",
        "\n",
        "# Message length * days of stay\n",
        "for i in message_lengths:\n",
        "  for j in stays:\n",
        "    df[i+'*'+j] = df[i] * df[j]\n",
        "\n",
        "# Message length * lead time\n",
        "for i in message_lengths:\n",
        "  for j in lead_times:\n",
        "    df[i+'*'+j] = df[i] * df[j]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hvuqr4WgwncE",
        "colab_type": "code",
        "outputId": "d0d1f140-269c-4472-fe4b-35b767fb0c7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>channel</th>\n",
              "      <th>reply_t</th>\n",
              "      <th>accept_t</th>\n",
              "      <th>replied</th>\n",
              "      <th>accepted</th>\n",
              "      <th>booked</th>\n",
              "      <th>1-10_interactions</th>\n",
              "      <th>11-20_interactions</th>\n",
              "      <th>21-30_interactions</th>\n",
              "      <th>&gt;30_interactions</th>\n",
              "      <th>0_reviews</th>\n",
              "      <th>1-10_reviews</th>\n",
              "      <th>11-20_reviews</th>\n",
              "      <th>21-30_reviews</th>\n",
              "      <th>&gt;30_reviews</th>\n",
              "      <th>1-30d_lead_time</th>\n",
              "      <th>31-60d_lead_time</th>\n",
              "      <th>61-90d_lead_time</th>\n",
              "      <th>&gt;90d_lead_time</th>\n",
              "      <th>1-5d_stay</th>\n",
              "      <th>6-10d_stay</th>\n",
              "      <th>11-15d_stay</th>\n",
              "      <th>&gt;15d_stay</th>\n",
              "      <th>0-150_char_message</th>\n",
              "      <th>151-300_char_message</th>\n",
              "      <th>301-450_char_message</th>\n",
              "      <th>&gt;450_char_message</th>\n",
              "      <th>1_guest</th>\n",
              "      <th>2_guests</th>\n",
              "      <th>3-4_guests</th>\n",
              "      <th>5-6_guests</th>\n",
              "      <th>&gt;6_guests</th>\n",
              "      <th>contact_me</th>\n",
              "      <th>past_booker</th>\n",
              "      <th>1-10_interactions*0-150_char_message</th>\n",
              "      <th>1-10_interactions*151-300_char_message</th>\n",
              "      <th>1-10_interactions*301-450_char_message</th>\n",
              "      <th>1-10_interactions*&gt;450_char_message</th>\n",
              "      <th>11-20_interactions*0-150_char_message</th>\n",
              "      <th>11-20_interactions*151-300_char_message</th>\n",
              "      <th>...</th>\n",
              "      <th>contact_me*31-60d_lead_time</th>\n",
              "      <th>contact_me*61-90d_lead_time</th>\n",
              "      <th>contact_me*&gt;90d_lead_time</th>\n",
              "      <th>contact_me*1_guest</th>\n",
              "      <th>contact_me*2_guests</th>\n",
              "      <th>contact_me*3-4_guests</th>\n",
              "      <th>contact_me*5-6_guests</th>\n",
              "      <th>contact_me*&gt;6_guests</th>\n",
              "      <th>0-150_char_message*1-5d_stay</th>\n",
              "      <th>0-150_char_message*6-10d_stay</th>\n",
              "      <th>0-150_char_message*11-15d_stay</th>\n",
              "      <th>0-150_char_message*&gt;15d_stay</th>\n",
              "      <th>151-300_char_message*1-5d_stay</th>\n",
              "      <th>151-300_char_message*6-10d_stay</th>\n",
              "      <th>151-300_char_message*11-15d_stay</th>\n",
              "      <th>151-300_char_message*&gt;15d_stay</th>\n",
              "      <th>301-450_char_message*1-5d_stay</th>\n",
              "      <th>301-450_char_message*6-10d_stay</th>\n",
              "      <th>301-450_char_message*11-15d_stay</th>\n",
              "      <th>301-450_char_message*&gt;15d_stay</th>\n",
              "      <th>&gt;450_char_message*1-5d_stay</th>\n",
              "      <th>&gt;450_char_message*6-10d_stay</th>\n",
              "      <th>&gt;450_char_message*11-15d_stay</th>\n",
              "      <th>&gt;450_char_message*&gt;15d_stay</th>\n",
              "      <th>0-150_char_message*1-30d_lead_time</th>\n",
              "      <th>0-150_char_message*31-60d_lead_time</th>\n",
              "      <th>0-150_char_message*61-90d_lead_time</th>\n",
              "      <th>0-150_char_message*&gt;90d_lead_time</th>\n",
              "      <th>151-300_char_message*1-30d_lead_time</th>\n",
              "      <th>151-300_char_message*31-60d_lead_time</th>\n",
              "      <th>151-300_char_message*61-90d_lead_time</th>\n",
              "      <th>151-300_char_message*&gt;90d_lead_time</th>\n",
              "      <th>301-450_char_message*1-30d_lead_time</th>\n",
              "      <th>301-450_char_message*31-60d_lead_time</th>\n",
              "      <th>301-450_char_message*61-90d_lead_time</th>\n",
              "      <th>301-450_char_message*&gt;90d_lead_time</th>\n",
              "      <th>&gt;450_char_message*1-30d_lead_time</th>\n",
              "      <th>&gt;450_char_message*31-60d_lead_time</th>\n",
              "      <th>&gt;450_char_message*61-90d_lead_time</th>\n",
              "      <th>&gt;450_char_message*&gt;90d_lead_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>book_it</td>\n",
              "      <td>nan</td>\n",
              "      <td>-0.100</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>contact_me</td>\n",
              "      <td>-0.119</td>\n",
              "      <td>nan</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>contact_me</td>\n",
              "      <td>-0.112</td>\n",
              "      <td>nan</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>contact_me</td>\n",
              "      <td>nan</td>\n",
              "      <td>-0.100</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>instant_book</td>\n",
              "      <td>-0.127</td>\n",
              "      <td>-0.100</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>contact_me</td>\n",
              "      <td>-0.103</td>\n",
              "      <td>nan</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>contact_me</td>\n",
              "      <td>-0.127</td>\n",
              "      <td>0.664</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>instant_book</td>\n",
              "      <td>nan</td>\n",
              "      <td>-0.100</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>instant_book</td>\n",
              "      <td>nan</td>\n",
              "      <td>-0.100</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>book_it</td>\n",
              "      <td>-0.126</td>\n",
              "      <td>nan</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows  128 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        channel  ...  >450_char_message*>90d_lead_time\n",
              "0       book_it  ...                                 0\n",
              "1    contact_me  ...                                 0\n",
              "2    contact_me  ...                                 0\n",
              "3    contact_me  ...                                 0\n",
              "4  instant_book  ...                                 0\n",
              "5    contact_me  ...                                 0\n",
              "6    contact_me  ...                                 0\n",
              "7  instant_book  ...                                 1\n",
              "8  instant_book  ...                                 0\n",
              "9       book_it  ...                                 0\n",
              "\n",
              "[10 rows x 128 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3vvrlMxIRGB",
        "colab_type": "text"
      },
      "source": [
        "## Feature scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHHKetTVLhIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scale reply_t and accept_t\n",
        "from sklearn import preprocessing\n",
        "sc_scale = preprocessing.StandardScaler().fit(df[['reply_t', 'accept_t']])\n",
        "df[['reply_t', 'accept_t']] = sc_scale.transform(df[['reply_t', 'accept_t']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9pSxmlB-2uQ",
        "colab_type": "text"
      },
      "source": [
        "## Split dataset by step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX-8Z34k-8gg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# All inquiries to predict reply, leave out Instant Book\n",
        "all_inquiries = df[df['channel'] != 'instant_book'].copy()\n",
        "\n",
        "# Rplied inquiries to predict acceptance\n",
        "replied_inquiries = all_inquiries[all_inquiries['replied'] == 1].copy()\n",
        "\n",
        "# Accepted inquiries to predict booking, leave out book it channel\n",
        "accepted_inquiries = replied_inquiries[replied_inquiries['accepted'] == 1].copy() \n",
        "accepted_inquiries = accepted_inquiries[accepted_inquiries['channel'] != 'book_it']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUcBsOB4rT9x",
        "colab_type": "code",
        "outputId": "ff462650-2ea3-4ceb-ff9e-5d3955ba1fe9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "all_inquiries.head(10)\n",
        "#replied_inquiries.info()\n",
        "#accepted_inquiries.info()"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>channel</th>\n",
              "      <th>reply_t</th>\n",
              "      <th>accept_t</th>\n",
              "      <th>replied</th>\n",
              "      <th>accepted</th>\n",
              "      <th>booked</th>\n",
              "      <th>1-10_interactions</th>\n",
              "      <th>11-20_interactions</th>\n",
              "      <th>21-30_interactions</th>\n",
              "      <th>&gt;30_interactions</th>\n",
              "      <th>0_reviews</th>\n",
              "      <th>1-10_reviews</th>\n",
              "      <th>11-20_reviews</th>\n",
              "      <th>21-30_reviews</th>\n",
              "      <th>&gt;30_reviews</th>\n",
              "      <th>1-30d_lead_time</th>\n",
              "      <th>31-60d_lead_time</th>\n",
              "      <th>61-90d_lead_time</th>\n",
              "      <th>&gt;90d_lead_time</th>\n",
              "      <th>1-5d_stay</th>\n",
              "      <th>6-10d_stay</th>\n",
              "      <th>11-15d_stay</th>\n",
              "      <th>&gt;15d_stay</th>\n",
              "      <th>0-150_char_message</th>\n",
              "      <th>151-300_char_message</th>\n",
              "      <th>301-450_char_message</th>\n",
              "      <th>&gt;450_char_message</th>\n",
              "      <th>1_guest</th>\n",
              "      <th>2_guests</th>\n",
              "      <th>3-4_guests</th>\n",
              "      <th>5-6_guests</th>\n",
              "      <th>&gt;6_guests</th>\n",
              "      <th>contact_me</th>\n",
              "      <th>past_booker</th>\n",
              "      <th>1-10_interactions*0-150_char_message</th>\n",
              "      <th>1-10_interactions*151-300_char_message</th>\n",
              "      <th>1-10_interactions*301-450_char_message</th>\n",
              "      <th>1-10_interactions*&gt;450_char_message</th>\n",
              "      <th>11-20_interactions*0-150_char_message</th>\n",
              "      <th>11-20_interactions*151-300_char_message</th>\n",
              "      <th>...</th>\n",
              "      <th>contact_me*31-60d_lead_time</th>\n",
              "      <th>contact_me*61-90d_lead_time</th>\n",
              "      <th>contact_me*&gt;90d_lead_time</th>\n",
              "      <th>contact_me*1_guest</th>\n",
              "      <th>contact_me*2_guests</th>\n",
              "      <th>contact_me*3-4_guests</th>\n",
              "      <th>contact_me*5-6_guests</th>\n",
              "      <th>contact_me*&gt;6_guests</th>\n",
              "      <th>0-150_char_message*1-5d_stay</th>\n",
              "      <th>0-150_char_message*6-10d_stay</th>\n",
              "      <th>0-150_char_message*11-15d_stay</th>\n",
              "      <th>0-150_char_message*&gt;15d_stay</th>\n",
              "      <th>151-300_char_message*1-5d_stay</th>\n",
              "      <th>151-300_char_message*6-10d_stay</th>\n",
              "      <th>151-300_char_message*11-15d_stay</th>\n",
              "      <th>151-300_char_message*&gt;15d_stay</th>\n",
              "      <th>301-450_char_message*1-5d_stay</th>\n",
              "      <th>301-450_char_message*6-10d_stay</th>\n",
              "      <th>301-450_char_message*11-15d_stay</th>\n",
              "      <th>301-450_char_message*&gt;15d_stay</th>\n",
              "      <th>&gt;450_char_message*1-5d_stay</th>\n",
              "      <th>&gt;450_char_message*6-10d_stay</th>\n",
              "      <th>&gt;450_char_message*11-15d_stay</th>\n",
              "      <th>&gt;450_char_message*&gt;15d_stay</th>\n",
              "      <th>0-150_char_message*1-30d_lead_time</th>\n",
              "      <th>0-150_char_message*31-60d_lead_time</th>\n",
              "      <th>0-150_char_message*61-90d_lead_time</th>\n",
              "      <th>0-150_char_message*&gt;90d_lead_time</th>\n",
              "      <th>151-300_char_message*1-30d_lead_time</th>\n",
              "      <th>151-300_char_message*31-60d_lead_time</th>\n",
              "      <th>151-300_char_message*61-90d_lead_time</th>\n",
              "      <th>151-300_char_message*&gt;90d_lead_time</th>\n",
              "      <th>301-450_char_message*1-30d_lead_time</th>\n",
              "      <th>301-450_char_message*31-60d_lead_time</th>\n",
              "      <th>301-450_char_message*61-90d_lead_time</th>\n",
              "      <th>301-450_char_message*&gt;90d_lead_time</th>\n",
              "      <th>&gt;450_char_message*1-30d_lead_time</th>\n",
              "      <th>&gt;450_char_message*31-60d_lead_time</th>\n",
              "      <th>&gt;450_char_message*61-90d_lead_time</th>\n",
              "      <th>&gt;450_char_message*&gt;90d_lead_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>book_it</td>\n",
              "      <td>nan</td>\n",
              "      <td>-0.100</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>contact_me</td>\n",
              "      <td>-0.119</td>\n",
              "      <td>nan</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>contact_me</td>\n",
              "      <td>-0.112</td>\n",
              "      <td>nan</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>contact_me</td>\n",
              "      <td>nan</td>\n",
              "      <td>-0.100</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>contact_me</td>\n",
              "      <td>-0.103</td>\n",
              "      <td>nan</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>contact_me</td>\n",
              "      <td>-0.127</td>\n",
              "      <td>0.664</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>book_it</td>\n",
              "      <td>-0.126</td>\n",
              "      <td>nan</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>contact_me</td>\n",
              "      <td>-0.010</td>\n",
              "      <td>nan</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>book_it</td>\n",
              "      <td>0.264</td>\n",
              "      <td>nan</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>book_it</td>\n",
              "      <td>nan</td>\n",
              "      <td>-0.100</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows  128 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       channel  ...  >450_char_message*>90d_lead_time\n",
              "0      book_it  ...                                 0\n",
              "1   contact_me  ...                                 0\n",
              "2   contact_me  ...                                 0\n",
              "3   contact_me  ...                                 0\n",
              "5   contact_me  ...                                 0\n",
              "6   contact_me  ...                                 0\n",
              "9      book_it  ...                                 0\n",
              "10  contact_me  ...                                 0\n",
              "11     book_it  ...                                 0\n",
              "12     book_it  ...                                 0\n",
              "\n",
              "[10 rows x 128 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmZvJ1q-CNjH",
        "colab_type": "text"
      },
      "source": [
        "# Model for all inquiries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7AjgJaVbLhSX"
      },
      "source": [
        "## Split training and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O76KeeX4Lvm6",
        "colab_type": "code",
        "outputId": "9b564d2f-4287-4ae5-b330-f246b6190588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Drop fake replies\n",
        "all_inquiries = all_inquiries.drop(all_inquiries[all_inquiries['replied'] == 1 & (all_inquiries.reply_t.isnull())].index)\n",
        "\n",
        "all_inquiries = all_inquiries.drop(['channel', 'reply_t', 'accept_t'], axis = 1)\n",
        "#all_inquiries = all_inquiries.drop(['channel', 'reply_t', 'accept_t', 'user_stage'], axis = 1)\n",
        "all_inquiries.info()"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 16083 entries, 1 to 26390\n",
            "Columns: 125 entries, replied to >450_char_message*>90d_lead_time\n",
            "dtypes: int64(125)\n",
            "memory usage: 15.5 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36aKnXo-Qn-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The 15% test data will kept aside, they won't be seen by the models until final test/comparison.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "model_train, model_test = train_test_split(all_inquiries, test_size=0.15, random_state = 3)\n",
        "model_train_x = model_train.drop(['replied', 'accepted', 'booked'], axis = 1)\n",
        "model_test_x = model_test.drop(['replied', 'accepted', 'booked'], axis = 1)\n",
        "model_train_y = model_train['replied']\n",
        "model_test_y = model_test['replied']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zDO4dH7_Lmj4"
      },
      "source": [
        "## Train model and find optimal hypermarameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hpe9PEAAi0Nt",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# helper function for printing out grid search results \n",
        "def print_grid_search_metrics(gs):\n",
        "    print (\"Best score: %0.3f\" % gs.best_score_)\n",
        "    print (\"Best parameters set:\")\n",
        "    best_parameters = gs.best_params_\n",
        "    for param_name in sorted(parameters.keys()):\n",
        "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eunIDvk3LoG7",
        "outputId": "d8146a9e-30bd-4cf2-f2d6-7997832d7536",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#from sklearn.ensemble import RandomForestClassifier\n",
        "#from sklearn.neighbors import KNeighborsClassifier \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Logistic Regression\n",
        "classifier_logistic = LogisticRegression()\n",
        "\n",
        "# Possible hyperparamter options for Logistic Regression Regularization\n",
        "# Penalty is choosed from L1 or L2\n",
        "# C is the lambda value(weight) for L1 and L2\n",
        "\n",
        "# ('l1', 1) ('l1', 5), ('l1', 10) ('l2', 1) ('l2', 5), ('l2', 10)\n",
        "parameters = {\n",
        "    'penalty':('l1', 'l2'), \n",
        "    'C':(1, 5, 10)\n",
        "}\n",
        "Grid_LR = GridSearchCV(LogisticRegression(),parameters, cv=5)\n",
        "Grid_LR.fit(model_train_x, model_train_y)"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=100, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=None, solver='lbfgs',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': (1, 5, 10), 'penalty': ('l1', 'l2')},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nN5rU0e-i0N1",
        "outputId": "6e45c675-7e27-4ccf-ccb7-031be23a7416",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# the best hyperparameter combination\n",
        "print_grid_search_metrics(Grid_LR)"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best score: 0.877\n",
            "Best parameters set:\n",
            "\tC: 1\n",
            "\tpenalty: 'l2'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TtkDsXgui0N3",
        "colab": {}
      },
      "source": [
        "# best model\n",
        "best_LR_model = Grid_LR.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opkj3SzSUd61",
        "colab_type": "text"
      },
      "source": [
        "## Model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2DaQpgxfl1Z",
        "colab_type": "text"
      },
      "source": [
        "### Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BLG2NYKCUXdL",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "# calculate accuracy, precision and recall, [[tn, fp],[]]\n",
        "def cal_evaluation(classifier, cm):\n",
        "    tn = cm[0][0]\n",
        "    fp = cm[0][1]\n",
        "    fn = cm[1][0]\n",
        "    tp = cm[1][1]\n",
        "    accuracy  = (tp + tn) / (tp + fp + fn + tn + 0.0)\n",
        "    precision = tp / (tp + fp + 0.0)\n",
        "    recall = tp / (tp + fn + 0.0)\n",
        "    print (classifier)\n",
        "    print (\"Accuracy is: %0.3f\" % accuracy)\n",
        "    print (\"precision is: %0.3f\" % precision)\n",
        "    print (\"recall is: %0.3f\" % recall)\n",
        "\n",
        "# print out confusion matrices\n",
        "def draw_confusion_matrices(confusion_matricies):\n",
        "    class_names = ['Not','reply']\n",
        "    for cm in confusion_matrices:\n",
        "        classifier, cm = cm[0], cm[1]\n",
        "        cal_evaluation(classifier, cm)\n",
        "        fig = plt.figure()\n",
        "        ax = fig.add_subplot(111)\n",
        "        cax = ax.matshow(cm, interpolation='nearest',cmap=plt.get_cmap('Reds'))\n",
        "        plt.title('Confusion matrix for %s' % classifier)\n",
        "        fig.colorbar(cax)\n",
        "        ax.set_xticklabels([''] + class_names)\n",
        "        ax.set_yticklabels([''] + class_names)\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('True')\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1f0f9543-c69e-4c0f-bf4e-f74dd417953f",
        "id": "hNfS1ZNKUgth",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "confusion_matrix(model_test_y, best_LR_model.predict(model_test_x))"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,  269],\n",
              "       [   0, 2144]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "eeb5cb89-0efa-4cc1-de96-0dd3a65e6b0e",
        "id": "MBKLeoqHUk53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# Confusion matrix, accuracy, precison and recall for random forest and logistic regression\n",
        "confusion_matrices = [\n",
        "    (\"Logistic Regression\", confusion_matrix(model_test_y, best_LR_model.predict(model_test_x))),\n",
        "    #(\"Logistic Regression\", confusion_matrix(yc_test,best_LR_model.predict(Xc_test))),\n",
        "]\n",
        "\n",
        "draw_confusion_matrices(confusion_matrices)"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic Regression\n",
            "Accuracy is: 0.889\n",
            "precision is: 0.889\n",
            "recall is: 1.000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAEQCAYAAAAJckeLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3debwcRb338c/3BEQ2ZUlACIRECCBwNUIuICKiXBFwIfqoLIoISOQKiIoLLveCKM/1URBEEQwSJcpiBNGIaIh4EUFAAsQEEpAAwSSEJUEIm0Dg9/xRNdA5nKVnOadnTr7vvPqV6eru6uqZOb+p6qruVkRgZmaN6aq6AGZmncxB1MysCQ6iZmZNcBA1M2uCg6iZWRMcRM3MmuAgCkhaU9JvJD0m6RdN5PNhSVe2smxVkfQWSXc2uO02kmZJelzSp1pdtlZo8vh+J+nQVpepnQ2l73arqZPGiUo6GPgssC3wODALOCUirm0y30OAY4HdImJF0wVtc5ICGBsR8wco//OA5RHxmRbldxKwVUR8pBX5VbXv/L4/BQTwGPBz4PMR8XyzeVt1OqYmKumzwBnA/wU2BkYBPwD2b0H2WwB/XxUCaBmSVmsyiy2A2yvad7t7Q0SsA7wVOAA4vNU7WAXew/YSEW0/Aa8GngA+2Mc6a5CC7P15OgNYIy/bE1gEHA88BCwBDsvLvgY8CzyX93EEcBLws0Leo0m1h9Xy/MeAe0i14XuBDxfSry1stxtwE6nWcROppltbdjXwdeC6nM+VwPBejq1W/i8Uyj8B2A/4O/AI8OXC+jsD1wOP5nW/D7wiL7smH8uT+XgPKOT/ReAB4Ke1tLzNlnkfO+b5TYGHgT17KOsfgeeBf+X8t86f35S8zX3AV4Guwnt2HXA6sAz4Rg95rvR5dFv2XlLAfjS/p68rLNsRuDW/v78g1fy+UXxPC+t+EVic170T2AvYp9t342+Fz+7jhW2PBOblbefW3qceyhqkWm1tfipwVmH+3aTW1aPAX4DX13Ms3T6/LuAE4O78vk4FNsjrvxL4WU5/lPTd3LiK7/ZQmCovQKlCpi/zCnIQ62Wdk4EbgI2AEflL+PXCl2xFXmd1UvB5Clg/L1/pj7SH+dH5D2A1YG1gObBNXrYJsH33LxqwAfBP4JC83UF5fsPCF+1uUpBZM89/s5djq5X/v3P5jyQFpAuBdYHtgaeBMXn9nYBd835Hk/7AP13Ir/sfcy3//0f6MVqTlweZI0kBYi1gOnBqH5/F1awcZKYAv85lHU0K/EcU3rMVpNMpqwFr9pDfSp9HIX1r0o/BO/L78gVgPvCKPN0HHJeXvZ8UEF8WRIFtgIXApoXPe8ve9l08PuCDpOD774CArYAtenlfXnzfSaeklgCfyfNvJP1A7gIMAw4FFuTPo8yxdP/8jiP9PWyW034IXJTX/wTwm/xZDiN9X15FBd/toTB1SnN+Q2Bp9N3c/jBwckQ8FBEPk2qYhxSWP5eXPxcRV5BqFts0WJ4XgB0krRkRSyKip6bru4C7IuKnEbEiIi4C7gDeU1jnxxHx94h4mlRTGNfHPp8jnf99DrgYGA58NyIez/ufC7wBICJujogb8n4XkP6A3lrimE6MiGdyeVYSEeeSAtSNpD+ur/STHwCShgEHAl/KZV0AnMbKn839EfG9XN6X7bsPBwC/jYgZ+X05lfRHuxsv/YicmT/zXwJ/7SWf50mBZjtJq0fEgoi4u2QZPg58KyJuimR+RNzXx/q3SHqS9MN2NemUFMBE4IcRcWNEPB8R5wPP5OMocyzdP7+jgK9ExKKIeIb0Y/CB3NR/jvQ3tVXe180RsbyQz2B/tztapwTRZcDwfs71bEr6ta65L6e9mEe3IPwUsE69BYmIJ0l/vEcBSyT9VtK2JcpTK9PIwvwDdZRnWbzUAVELNA8Wlj9d217S1pIul/SApOWk88jD+8gb4OGI+Fc/65wL7AB8L/9hljGcVHvq/tkU34eFJfPqbqX3OCJeyHmNzMsWR64a9bWfSB1snyYFmockXSxp057W7cHmpFpXWTuSPqcDSLXOtXP6FsDxkh6tTTnvTUseS/fPbwvgskJe80g/FhuTmvvTgYsl3S/pW/nHo6rvdkfrlCB6PelXeUIf69xP+uLUjMppjXiS1NSpeU1xYURMj4h3kGpkd5CCS3/lqZVpcYNlqsfZpHKNjYhXAV8mNTX70ucwDUnrkM4znwecJGmDkmVZSqr5dP9siu9Do0NEVnqPJYkUeBaTmsojc1rN5r1lFBEXRsTuOb8gNY3LlG0h6ZxxabnGOpX0vf7vQj6nRMR6hWmtXMsrcyzdy7kQ2Ldbfq+MiMW5Nvu1iNiOVGt/N/DRXLZ2/263nY4IohHxGOnLdpakCZLWkrS6pH0lfSuvdhHwVUkjJA3P6/+swV3OAvaQNErSq4Ev1RZI2ljS/pLWJgX2J0hNoO6uALaWdLCk1SQdAGwHXN5gmeqxLunc1hO5JvGf3ZY/CLy2zjy/C8yMiI8DvwXOKbNRrj1PBU6RtK6kLUjD1Or9bLokvbIwrZHzfZekvSStTuo4fIZ0Pvx6Us3rmPz+70/qcHuZPK717TnPf5Fq9bXP9EFgtKTe/lZ+BHxO0k5KtsrHWMY3gSMlvYYUrI6StEvOZ21J75K0bj3HUnAO6T3fIh/jiLwdkt4m6d/yqZblpB+5Fzrku912OiKIAkTEaaQ/vq+SOlUWAscAv8qrfAOYCcwG5gC35LRG9jWD1Ps5G7iZlb8cXbkc95N6rN/Ky4MUEbGM9At/POl0xBeAd0fE0kbKVKfPAQeTekbPJR1L0UnA+bmp96H+Mst/fPvw0nF+FthR0odLludYUu3+HuBaUofY5JLb1hxECm616e6IuBP4CPA9Uo33PcB7IuLZiHiW1AFzBKkH+iOkz7Gn0xBrkALaUlIzdCNe+uGsXXyxTNIt3TeMiF8Ap+Rjepz0fSxVS4+IOaTREp+PiJmkzrvvkzpp5pM6c6jzWGq+C0wDrpT0OKmTaZe87DXAJaQAOg/4Ey/16Lf7d7vtdNRg+1VBHpD9nYg4Ps9/DlgnIk7qY5sJpHGucwenlJ1J0o3AORHx44rLcTXwuRw4G82jLY7FOqgmugp5Bnh/PiVR1gRSc8oKJL1V0mtyk/NQ4PXA71u8D/XR1G/lfgb8WKwxDqLtZwUwCXjZJZOSRkv6o6TZkq7K52x3Iw04/7bS9ep1dXIMcdsAfyM1gY8HPhARS5rNNH8Od0qaAtwG/Jekm/Ln8rXCOndIukDSPEmXSFqrWz6HSzqjMH+kpNMH81iseW7OtxlJT5CGkMwmjfs8ktycl/Qb4JKIOF/S4cB7I2KCpJ8Al0fEJZUVfBUiaTTp/O5upEHqHyANYBfpPOS3gH+QrvjZPSKukzQZmBsRp9aa86Te778B20bEc5L+Anwinyu1DuGaaBvKA5+nAN3vgPQmUgcGpI6A3QezXLaS+yLiBmDvPN1K6szcFhib11kYEdfl1z+j2+cVEU+QLpN9dx5FsboDaOfxjQra1xmkP0p3HLSnJ/P/Av4nIn5YXJhrq92beT01+35EGsd7B/6sO5Jrom0qIh4hjYM8opD8F9IllJAuc/1zfv04aWyoDb7pwOFKFyMgaaSkjfKyUZLelF8fTBretZKIuJE0cP5g0lhn6zAOou3tNFa+XPNY4DBJs0nXnh+X0y8GPi/pVncsDa6IuJJ0iuV6SXNI4y9rP2h3AkdLmgesT7qSrCdTgesi4p8DXV5rPXcsmQ2A3Jy/PCJ2KLHu5cDpEXHVQJfLWs81UbOKSFpP0t+Bpx1AO5dromZmTXBN1MysCQ6iZmZNcBDtMJImVl0GK8+f19DnINp5/EfZWfx5DXEOomZmTRiSvfPDh28Yo0eNqroYA+LhpcsYMXzDqovReiuerboEA+LhZf9kxIbrV12MAXHznLlLI2JEo9tvrtXiXyWfDLOUF6ZHxD6N7msgDclr50ePGsXMa6+uuhhWhxce6usBmdaOho15Q1Mf2r8I/s+Lz+nr2w95vJ776w6qIRlEzaz9iaFxPtFB1MwqIWA19fcQ2qyNzzo6iJpZZbpKxlAHUTOzHrg5b2bWICG6yjbn25iDqJlVxjVRM7MGiTrOibYxB1Ezq4ZgmJvzZmaN8ThRM7MmDYXm/FD4ITCzDtVVcuqPpM0l/a+kuZJul3RcTt9A0gxJd+X/18/pknSmpPmSZkvasZDXoXn9uyQdWuYYzMwGXepYUqmphBXA8RGxHbAr6Smr2wEnAFdFxFjgqjwPsC8wNk8TyU9ilbQBcCKwC7AzcGIt8PbGQdTMKpEu+yw39ScilkTELfn148A8YCSwP3B+Xu18YEJ+vT8wJZIbgPUkbQK8E5gREY/kR1jPAPq8e5TPiZpZZeqoxQ2XNLMwPykiJvW0Yn5c9RuBG4GNI2JJXvQAsHF+PRJYWNhsUU7rLb1XDqJmVpkuSvcsLY2I8f2tJGkd4FLg0xGxXIVTARERklp+Fb6b82ZWidpg+zJTqfyk1UkB9IKI+GVOfjA308n/P5TTFwObFzbfLKf1lt4rB1Ezq0wLe+cFnAfMi4jvFBZNA2o97IcCvy6kfzT30u8KPJab/dOBvSWtnzuU9s5pvXJz3swqoTpqmSW8GTgEmCNpVk77MvBNYKqkI4D7gA/lZVcA+wHzgaeAwwAi4hFJXwduyuudHBGP9LVjB1Ezq0zpmzL3IyKuhV5PsO7Vw/oBHN1LXpOByWX37SBqZpXwZZ9mZk0aCpd9OoiaWSWE6hni1LYcRM2sMq6Jmpk1SMAwB1Ezs8a5OW9m1qAWjxOtjIOomVXGQ5zMzJowBCqiDqJmVo3aTZk7nYOomVXGzXkzsyZ0fj3UQdTMKiQ3583MGiNcEzUza4rPiZqZNWEItOaHxA+BmXWgdD9RlZr6zUuaLOkhSbcV0n4uaVaeFtTueC9ptKSnC8vOKWyzk6Q5kuZLOlMlTtq6JmpmlWlhRfQnwPeBKbWEiDjgxf1IpwGPFda/OyLG9ZDP2cCRpMctX0F65vzv+tqxa6JmVplWPe0zIq4BenwWUq5Nfgi4qK888tNAXxURN+THh0wBJvR7DP0Xz8xsIKj0P2C4pJmFaWIdO3oL8GBE3FVIGyPpVkl/kvSWnDYSWFRYZ1FO65Ob82ZWiTqHOC2NiPEN7uogVq6FLgFGRcQySTsBv5K0fYN5O4iaWUUG4VZ4klYD3g/sVEuLiGeAZ/LrmyXdDWwNLAY2K2y+WU7rk5vzZlaZVvXO9+E/gDsi4sVmuqQRkobl168FxgL3RMQSYLmkXfN51I8Cv+7/GMzMKqA6pn7zki4Crge2kbRI0hF50YG8vENpD2B2HvJ0CXBURNQ6pT4J/AiYD9xNPz3z4Oa8mVWoVYPtI+KgXtI/1kPapcClvaw/E9ihnn07iJpZZYbABUsOomZWHQ2BMOogamaV8COTzcyaNARiqIOomVVnKDTnKxviJCnyTQFq85+TdFI/20yQtN2AF87MBoVUbmpnVY4TfQZ4v6ThdWwzAXAQNRsC0q3wyk3trMryrQAmAZ/pviDf7++PkmZLukrSKEm7Ae8Fvp3vAbjlYBfYzFqrVYPtq1R1kD8L+LCkV3dL/x5wfkS8HrgAODMi/gJMAz4fEeMi4u5BLquZtViXVGpqZ5UG0YhYTrpn36e6LXoTcGF+/VNg9/7ykjSxdpush5cua21BzazlWnnZZ5WqrokCnAEcAazdTCYRMSkixkfE+BHDN2xNycxs4Eio5NTOKg+i+cL/qaRAWvMX0o0DAD4M/Dm/fhxYd/BKZ2YDqVV3tq9S5UE0Ow0o9tIfCxwmaTZwCHBcTr8Y+Hy+I7U7lsw6nLpUampnlQ22j4h1Cq8fBNYqzN8HvL2Hba7DQ5zMhgQJutqlGtcEX7FkZpVp9/OdZTiImlllhkAMbZtzoma2CmpV77ykyZIeknRbIe0kSYvzxTmzJO1XWPYlSfMl3SnpnYX0fXLafEknlDkGB1Ezq4Ro6bXzPwH26SH99HxxzriIuAIg33/jQGD7vM0PJA3Lz106C9iX1PdyUJl7dbg5b2bVEC27GikirpE0uuTq+wMX56d+3itpPrBzXjY/Iu4BkHRxXnduX5m5JmpmFRFdXeWmJhyT78ExWdL6OW0ksLCwzqKc1lt6nxxEzawSAtRVbgKG1y7rztPEErs4G9gSGAcsIY1Hbzk3582sGqpriNPSiBhfT/Z5/HnalXQucHmeXQxsXlh1s5xGH+m9ck3UzCozkDdllrRJYfZ9QK3nfhpwoKQ1JI0BxgJ/BW4CxkoaI+kVpM6naf3txzVRM6tMqwbbS7oI2JPU7F8EnAjsKWkcEMAC4BMAEXG7pKmkDqMVwNER8XzO5xhgOjAMmBwRt/e3bwdRM6tMqwbbR8RBPSSf18f6pwCn9JB+BXBFPft2EDWzSkgwrM1vLlKGg6iZVcbXzpuZNWEIxFAHUTOrRu2yz07nIGpm1VD733C5DAdRM6uMO5bMzBrk5ryZWZPcO29m1qgmLulsJw6iZlYZ10TNzJowBGKog6iZVUOCrmGdH0UdRM2sIuUeQtfuHETNrDoeJ2pm1gTXRM3MGlTf40HaloOomVVEMKzzn1DU+UdgZh1JAnWp1NR/Xpos6SFJtxXSvi3pjvzI5MskrZfTR0t6WtKsPJ1T2GYnSXMkzZd0pkpUlR1Ezaw6rXtS3U+AfbqlzQB2iIjXA38HvlRYdndEjMvTUYX0s4EjSQ+vG9tDni/jIGpmlWlVTTQirgEe6ZZ2ZUSsyLM3kB6B3HtZ0tNBXxURN0REAFOACf3t20HUzKpTviY6XNLMwjSxzj0dDvyuMD9G0q2S/iTpLTltJLCosM6inNYndyyZWTWkesaJLo2I8Y3tRl8hPRr5gpy0BBgVEcsk7QT8StL2jeQNDqJmViENcO+8pI8B7wb2yk10IuIZ4Jn8+mZJdwNbA4tZucm/WU7rk5vzZlaN2l2ZW9Ox9PLspX2ALwDvjYinCukjJA3Lr19L6kC6JyKWAMsl7Zp75T8K/Lq//bgmamaVUYuqcZIuAvYknTtdBJxI6o1fA5iRRyrdkHvi9wBOlvQc8AJwVETUOqU+SerpX5N0DrV4HrVHDqJmVp0WXbEUEQf1kHxeL+teClzay7KZwA717NtB1Myq4ad9mpk1ydfOm5k1Rhr43vnB0O8RKPmIpP/O86Mk7TzwRTOzIa9L5aY2VuZn4AfAm4DaidvHgbMGrERmtoooObypzZv8ZZrzu0TEjpJuBYiIf0p6xQCXy8xWAavK/USfywNTA9JAVdLYKjOzxom2b6qXUSaInglcBmwk6RTgA8BXB7RUZrZKGAodS/0G0Yi4QNLNwF6k344JETFvwEtmZkNbB5zvLKPfICppFPAU8JtiWkT8YyALZmZD36oy2P63pPOhAl4JjAHuBBq+dZSZGbBq1EQj4t+K85J2JF2kb2bWuFWoY2klEXGLpF0GojC26vrkmDdXXQSrwCoxxEnSZwuzXcCOwP0DViIzW0UMjUcml6mJrlt4vYJ0jrTH20iZmZVWuylzh+sziOZB9utGxOcGqTxmtioZAkG017q0pNUi4nnAJ6vMbAAIurrKTf3lJE2W9JCk2wppG0iaIemu/P/6OV2SzpQ0X9Ls3Fle2+bQvP5dkg4tcxR9le6v+f9ZkqZJOkTS+2tTmczNzPrUuhuQ/ATYp1vaCcBVETEWuCrPA+xLeq7SWGAicHYqijYgPVZkF2Bn4MRa4O1LmXOirwSWAW/npfGiAfyyxLZmZj1r4TnRiLhG0uhuyfuTnrsEcD5wNfDFnD4lP/3zBknrSdokrzuj9rwlSTNIgfmivvbdVxDdKPfM38ZLwfPFMvd3UGZmfRMMG1Z25eGSZhbmJ0XEpH622Tg/wRPgAWDj/HoksLCw3qKc1lt6n/oKosOAdVg5eNY4iJpZ88rXRJdGxPhGdxMRIWlA4lZfQXRJRJw8EDs1MxuEIU4PStokIpbk5vpDOX0xsHlhvc1y2mJeav7X0q/ubyd9dSx1/tgDM2tvA3tn+2lArYf9UODXhfSP5l76XYHHcrN/OrC3pPVzh9LeOa1PfdVE92q05GZm/VOp4UulcpIuItUih0taROpl/yYwVdIRwH3Ah/LqVwD7AfNJd6g7DCAiHpH0deCmvN7JtU6mvvQaRMtsbGbWMNGyIBoRB/Wy6GWVwdwrf3Qv+UwGJtezbz8y2cyqMwSuWHIQNbNKCKEW1USr5CBqZtVxTdTMrEGrwl2czMwGlIOomVmj6rrss205iJpZNdycNzNrkoOomVmjWnfFUpUcRM2sOq6Jmpk1yOdEzcya4d55M7PmuCZqZtYgN+fNzJrh3nkzs+YMgZpo5/8MmFlnEtA1rNzUX1bSNpJmFablkj4t6SRJiwvp+xW2+ZKk+ZLulPTORg/DNVEzq4igq2XPnb8TGAcgaRjpoXOXkR79cXpEnLrSnqXtgAOB7YFNgT9I2joinq93366Jmll11FVuqs9ewN0RcV8f6+wPXBwRz0TEvaTnLe3cyCE4iJpZdQbmaZ8HAhcV5o+RNFvS5PwUT4CRwMLCOotyWt0cRM2sGsq982Wm9BTPmYVpYs9Z6hXAe4Ff5KSzgS1JTf0lwGmtPgyfEzWz6pSvZS6NiPEl1tsXuCUiHgSo/Z92pXOBy/PsYmDzwnab5bS6uSZqZtVpUe98wUEUmvKSNiksex9wW349DThQ0hqSxgBjgb82cgiuiZpZNdTawfaS1gbeAXyikPwtSeOAABbUlkXE7ZKmAnOBFcDRjfTMg4OomVWphYPtI+JJYMNuaYf0sf4pwCnN7tdB1MyqU//wpbbjIGpm1VDrBttXyUHUzKpTX6dRW3IQNbOKyM15M7OGCTfnzcyaMgRuhecgambVcXPezKxB7p03M2uSe+fNzBrl3nkzs8a5d97MrEmuiZqZNWEIDHFq258BSVdLKnMTVjPrSHXd2b5tDUpNVJIARcQLg7E/M+sAtUcmd7gBC/GSRufnOU8h3U36vyTdlB8Y9bXCOndIukDSPEmXSFqrWz6HSzqjMH+kpNMHqtxmNlhKPqSuzZv8A11PHgv8APgM6Ul6O5MeGLWTpD3yOtsAP4iI1wHLgU92y2Mq8B5Jq+f5w4DJ3XckaWLtIVYPL13W+iMxs9YbAs35gS7dfRFxA7B3nm4FbgG2JQVYgIURcV1+/TNg92IGEfEE8Efg3ZK2BVaPiDnddxQRkyJifESMHzF8w+6LzazdiJbWRCUtkDRH0ixJM3PaBpJmSLor/79+TpekMyXNz63jHRs9jIEOok/m/wX8T0SMy9NWEXFeXhbdtuk+D/Aj4GOkWuiPB6SkZjbI8mD7MlN5b8sxptYpfQJwVUSMBa7K85CeCjo2TxNJj1ZuyGDVk6cDh0taB0DSSEkb5WWjJL0pvz4YuLb7xhFxI+nxpgdTeJKfmXW41j/ts7v9gfPz6/OBCYX0KZHcAKzX7cmg5Q+hmdKVFRFXAhcC10uaA1wCrJsX3wkcLWkesD69/yJMBa6LiH8OdHnNbBDUbkBSZoLhtT6PPE3sIccArpR0c2H5xhGxJL9+ANg4vx4JLCxsuyin1W3AhjhFxAJgh8L8d4HvFteRNBpYEREf6WH7Pbsl7Q64V95sKCnfVF9aaKL3ZveIWJxbuTMk3VFcGBEhqafThU1p724vQNJ6kv4OPB0RV1VdHjNroRZ2LEXE4vz/Q8BlpNFAD9aa6fn/h/Lqi0mnCGs2y2l1qzSIRsSCiNihn3UejYitI+KDg1UuMxsMretYkrS2pHVrr0mjgW4DpgGH5tUOBX6dX08DPpp76XcFHis0++via+fNrDJq3UD6jYHLcn6rARdGxO8l3QRMlXQEcB/wobz+FcB+wHzgKdLIn4Y4iJpZNSToak0Iioh7gDf0kL4M2KuH9ACObsW+HUTNrDq+n6iZWRN8P1EzswbVLvvscA6iZlYRP2PJzKw5romamTVIgmGdf1NmB1Ezq46b82ZmTXBz3sysUe5YMjNrjmuiZmYNkmBY54egzj8CM+tYLbwBSWUcRM2sOj4nambWIF/2aWbWDPfOm5k1ZwjURDv/Z8DMOlPtss8yU79ZaXNJ/ytprqTbJR2X00+StFjSrDztV9jmS5LmS7pT0jsbPQzXRM2sOq1rzq8Ajo+IW/Kzlm6WNCMvOz0iTl1pt9J2wIHA9sCmwB8kbR0Rz9e7Y9dEzaw6LXraZ0QsiYhb8uvHgXn0/Rz5/YGLI+KZiLiX9KylnRs5BAdRM6uQSk4MlzSzME3sNUdpNPBG4MacdIyk2ZImS1o/p40EFhY2W0TfQbdXDqJmVpGStdBUE10aEeML06Qec5TWAS4FPh0Ry4GzgS2BccAS4LRWH4XPiZpZdVrYOy9pdVIAvSAifgkQEQ8Wlp8LXJ5nFwObFzbfLKfVzTVRM6uGSB1LZab+skrXj54HzIuI7xTSNyms9j7gtvx6GnCgpDUkjQHGAn9t5DBcEzWz6rSuIvpm4BBgjqRZOe3LwEGSxgEBLAA+ARARt0uaCswl9ewf3UjPPDiImlmlWhNFI+LaXjK7oo9tTgFOaXbfDqJmVpFyw5fanYOomVXHQdTMrAm+AYmZWTNcEzUza0zJSzrbnYOomVXHQdTMrBkOomZmDfOD6szMGubHg5iZNcc1UTOzBvlpn2ZmzXIQNTNrnGuiZmZN6PwY6iBqZlVx77yZWePcsWRm1qzOD6KdX5c2s87VoufOp6y0j6Q7Jc2XdMIAl/xFDqJmVpG6Hpncd07SMOAsYF9gO9KzlbYb4AMAHETNrEotetonsDMwPyLuiYhngYuB/Qe07NmQPCd6862zlmrt9e6ruhwDZDiwtOpCWGlD+fPaopmNb7511nStvd7wkqu/UtLMwvykiJhUmB8JLCzMLwJ2aaZ8ZQ3JIBoRI6ouw0CRNDMixlddDivHn1fvImKfqsvQCm7Om9lQsBjYvDC/WU4bcA6iZjYU3ASMlTRG0iuAA4Fpg7HjIdmcH+Im9b+KtRF/XoMgIlZIOgaYDgwDJkfE7YOxb0XEYOzHhgBJzwNzSD++84BDI+KpBvP6CXB5RFwi6UfAdyJibi/r7gk8GxF/qdYw5w0AAAIeSURBVHMfC4DxETFUO3asDbg5b/V4OiLGRcQOwLPAUcWFkhpq2UTEx3sLoNmewG6N5G020BxErVF/BraStKekP0uaBsyVNEzStyXdJGm2pE8AKPl+vqLkD8BGtYwkXS1pfH69j6RbJP1N0lWSRpOC9WckzZL0FkkjJF2a93GTpDfnbTeUdKWk23PttvOvKbS253OiVrdc49wX+H1O2hHYISLulTQReCwi/l3SGsB1kq4E3ghsQ7qaZGNgLjC5W74jgHOBPXJeG0TEI5LOAZ6IiFPzehcCp0fEtZJGkc6DvQ44Ebg2Ik6W9C7giAF9I8xwELX6rClpVn79Z+A8UjP7rxFxb07fG3i9pA/k+VcDY4E9gIsi4nngfkl/7CH/XYFranlFxCO9lOM/gO0KT4p8laR18j7en7f9raR/NnicZqU5iFo9no6IccWEHMieLCYBx0bE9G7r7dfCcnQBu0bEv3ooi9mg8jlRa7XpwH9KWh1A0taS1gauAQ7I50w3Ad7Ww7Y3AHtIGpO33SCnPw6sW1jvSuDY2oykWmC/Bjg4p+0LrN+yozLrhYOotdqPSOc7b5F0G/BDUovnMuCuvGwKcH33DSPiYWAi8EtJfwN+nhf9BnhfrWMJ+BQwPndczeWlUQJfIwXh20nN+n8M0DGavcjjRM3MmuCaqJlZExxEzcya4CBqZtYEB1EzsyY4iJqZNcFB1MysCQ6iZmZN+P8GfBU3AoSwbgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7ENOi-Nfqgp",
        "colab_type": "text"
      },
      "source": [
        "### ROC & AUC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "78mNLVfGfkgJ",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn import metrics\n",
        "\n",
        "# Use predict_proba to get the probability results of Logistic Regression\n",
        "y_pred_lr = best_LR_model.predict_proba(model_test_x)[:, 1]\n",
        "fpr_lr, tpr_lr, _ = roc_curve(model_test_y, y_pred_lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "08318b82-fd4f-42a6-bb1f-de3c067e5003",
        "id": "Kp8kqcV8fv3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# ROC Curve\n",
        "plt.figure(1)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr_lr, tpr_lr, label='LR')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve - LR Model')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3fb111f3-36c2-4ba6-93f9-d97b277f51de",
        "id": "e8ZmgKd0fx_k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# AUC score\n",
        "metrics.auc(fpr_lr,tpr_lr)"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7152249902901848"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAfrAIoMoaxt",
        "colab_type": "text"
      },
      "source": [
        "## Feature selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "scrolled": true,
        "outputId": "714c22ad-00ed-41d5-8c82-1fec80b08437",
        "id": "QQ4y3hcA3uiz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# Store the coef for feature selection\n",
        "res = pd.DataFrame(columns=['Feature', 'Coef'])\n",
        "\n",
        "for k,v in sorted(zip(map(lambda x: round(x, 4), best_LR_model.fit(model_train_x, model_train_y).coef_[0]), \\\n",
        "                      model_train_x.columns), key=lambda k_v:(-abs(k_v[0]),k_v[1])):\n",
        "    #print (v + \": \" + str(k))\n",
        "    res = res.append({'Feature': v, 'Coef': k}, ignore_index=True)\n"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jyb4rokUCScp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "d0df22fa-75b5-44ab-fa6b-8ebf99ca91ae"
      },
      "source": [
        "res"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature</th>\n",
              "      <th>Coef</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1-10_interactions</td>\n",
              "      <td>-1.603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0_reviews</td>\n",
              "      <td>-0.815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11-20_interactions*0-150_char_message</td>\n",
              "      <td>0.803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11-20_interactions</td>\n",
              "      <td>0.756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1-10_interactions*1-30d_lead_time</td>\n",
              "      <td>-0.713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>&gt;450_char_message*&gt;90d_lead_time</td>\n",
              "      <td>0.024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>301-450_char_message*61-90d_lead_time</td>\n",
              "      <td>0.023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>past_booker*11-20_interactions</td>\n",
              "      <td>-0.021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>151-300_char_message*1-5d_stay</td>\n",
              "      <td>0.011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>301-450_char_message*&gt;90d_lead_time</td>\n",
              "      <td>-0.001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>122 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   Feature   Coef\n",
              "0                        1-10_interactions -1.603\n",
              "1                                0_reviews -0.815\n",
              "2    11-20_interactions*0-150_char_message  0.803\n",
              "3                       11-20_interactions  0.756\n",
              "4        1-10_interactions*1-30d_lead_time -0.713\n",
              "..                                     ...    ...\n",
              "117       >450_char_message*>90d_lead_time  0.024\n",
              "118  301-450_char_message*61-90d_lead_time  0.023\n",
              "119         past_booker*11-20_interactions -0.021\n",
              "120         151-300_char_message*1-5d_stay  0.011\n",
              "121    301-450_char_message*>90d_lead_time -0.001\n",
              "\n",
              "[122 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rG0IaIqmoOJr",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "res.to_csv('mod1_res.csv')\n",
        "files.download('mod1_res.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWFWtbYB4vlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#interaction = res[res.Feature.str.contains('interaction', regex=False)]\n",
        "#res_pos = res[res.Coef >= 0]\n",
        "#res_pos.style.background_gradient(subset=['Coef'], cmap='BuGn')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La8ovQ8EVbJm",
        "colab_type": "text"
      },
      "source": [
        "# Model for replied inquiries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EOCZdgt3VlHI"
      },
      "source": [
        "## Split training and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h3XXo6HbVm_0",
        "outputId": "850abc36-87ed-473a-cbc1-90b2defaee0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "replied_inquiries = replied_inquiries.drop(['channel', 'accept_t'], axis = 1)\n",
        "replied_inquiries = replied_inquiries.dropna() # drop fake replies\n",
        "replied_inquiries.info()"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 14129 entries, 1 to 26390\n",
            "Columns: 126 entries, reply_t to >450_char_message*>90d_lead_time\n",
            "dtypes: float64(1), int64(125)\n",
            "memory usage: 13.7 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N8l1N3avVo99",
        "colab": {}
      },
      "source": [
        "# The 15% test data will kept aside, they won't be seen by the models until final test/comparison.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "model_train, model_test = train_test_split(replied_inquiries, test_size=0.15, random_state = 3)\n",
        "model_train_x = model_train.drop(['replied', 'accepted', 'booked'], axis = 1)\n",
        "model_test_x = model_test.drop(['replied', 'accepted', 'booked'], axis = 1)\n",
        "model_train_y = model_train['accepted']\n",
        "model_test_y = model_test['accepted']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "570dYcpMVsIb"
      },
      "source": [
        "## Train model and find optimal hypermarameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yKsSUiWdVtdL",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# helper function for printing out grid search results \n",
        "def print_grid_search_metrics(gs):\n",
        "    print (\"Best score: %0.3f\" % gs.best_score_)\n",
        "    print (\"Best parameters set:\")\n",
        "    best_parameters = gs.best_params_\n",
        "    for param_name in sorted(parameters.keys()):\n",
        "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "simBWgxAVyMm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a2fd2fad-ccac-48f3-8789-c8ce5248978a"
      },
      "source": [
        "#from sklearn.ensemble import RandomForestClassifier\n",
        "#from sklearn.neighbors import KNeighborsClassifier \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Logistic Regression\n",
        "classifier_logistic = LogisticRegression()\n",
        "\n",
        "# Possible hyperparamter options for Logistic Regression Regularization\n",
        "# Penalty is choosed from L1 or L2\n",
        "# C is the lambda value(weight) for L1 and L2\n",
        "\n",
        "# ('l1', 1) ('l1', 5), ('l1', 10) ('l2', 1) ('l2', 5), ('l2', 10)\n",
        "parameters = {\n",
        "    'penalty':('l1', 'l2'), \n",
        "    'C':(1, 5, 10)\n",
        "    #'C':np.logspace (2, 5, num=20)\n",
        "}\n",
        "Grid_LR = GridSearchCV(LogisticRegression(),parameters, cv=5)\n",
        "Grid_LR.fit(model_train_x, model_train_y)"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=100, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=None, solver='lbfgs',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': (1, 5, 10), 'penalty': ('l1', 'l2')},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "bd43b0de-f9c2-42a8-978e-a2e3e873eab6",
        "id": "TC8ObzsAV0LE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# the best hyperparameter combination\n",
        "print_grid_search_metrics(Grid_LR)\n"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best score: 0.761\n",
            "Best parameters set:\n",
            "\tC: 1\n",
            "\tpenalty: 'l2'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BiF6QQ2BV1lr",
        "colab": {}
      },
      "source": [
        "# best model\n",
        "best_LR_model = Grid_LR.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2ZtggrS2V3UI"
      },
      "source": [
        "## Model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIkNu2H7jsNS",
        "colab_type": "text"
      },
      "source": [
        "### Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XG22kAAiV46H",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "# calculate accuracy, precision and recall, [[tn, fp],[]]\n",
        "def cal_evaluation(classifier, cm):\n",
        "    tn = cm[0][0]\n",
        "    fp = cm[0][1]\n",
        "    fn = cm[1][0]\n",
        "    tp = cm[1][1]\n",
        "    accuracy  = (tp + tn) / (tp + fp + fn + tn + 0.0)\n",
        "    precision = tp / (tp + fp + 0.0)\n",
        "    recall = tp / (tp + fn + 0.0)\n",
        "    print (classifier)\n",
        "    print (\"Accuracy is: %0.3f\" % accuracy)\n",
        "    print (\"precision is: %0.3f\" % precision)\n",
        "    print (\"recall is: %0.3f\" % recall)\n",
        "\n",
        "# print out confusion matrices\n",
        "def draw_confusion_matrices(confusion_matricies):\n",
        "    class_names = ['Not','Accept']\n",
        "    for cm in confusion_matrices:\n",
        "        classifier, cm = cm[0], cm[1]\n",
        "        cal_evaluation(classifier, cm)\n",
        "        fig = plt.figure()\n",
        "        ax = fig.add_subplot(111)\n",
        "        cax = ax.matshow(cm, interpolation='nearest',cmap=plt.get_cmap('Reds'))\n",
        "        plt.title('Confusion matrix for %s' % classifier)\n",
        "        fig.colorbar(cax)\n",
        "        ax.set_xticklabels([''] + class_names)\n",
        "        ax.set_yticklabels([''] + class_names)\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('True')\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "01234e44-2e3e-44d9-9782-5255fae278f5",
        "id": "D2JH4YEVV6lf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "confusion_matrix(model_test_y, best_LR_model.predict(model_test_x))"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1252,   97],\n",
              "       [ 438,  333]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b0261f61-8b27-41e4-c8c0-c5abe07d2610",
        "id": "Z9HwLlUFV75R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# Confusion matrix, accuracy, precison and recall for random forest and logistic regression\n",
        "confusion_matrices = [\n",
        "    (\"Logistic Regression\", confusion_matrix(model_test_y, best_LR_model.predict(model_test_x))),\n",
        "    #(\"Logistic Regression\", confusion_matrix(yc_test,best_LR_model.predict(Xc_test))),\n",
        "]\n",
        "\n",
        "draw_confusion_matrices(confusion_matrices)"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic Regression\n",
            "Accuracy is: 0.748\n",
            "precision is: 0.774\n",
            "recall is: 0.432\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uUSaOrsmjkKa"
      },
      "source": [
        "### ROC & AUC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XSG4xuoCjl04",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn import metrics\n",
        "\n",
        "# Use predict_proba to get the probability results of Logistic Regression\n",
        "y_pred_lr = best_LR_model.predict_proba(model_test_x)[:, 1]\n",
        "fpr_lr, tpr_lr, _ = roc_curve(model_test_y, y_pred_lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b846a7e5-4e6c-45b7-813a-cbc26e0130db",
        "id": "1IqlhZ-ejozq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# ROC Curve\n",
        "plt.figure(1)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr_lr, tpr_lr, label='LR')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve - LR Model')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXhU9fX48fcxQRAFlEXLHpawBKSKFMouiygqILUqgigaWYWiQC2IIlJKAdkE2ZVFFAUVKrZ8pVZr6Q8FWUVAgciOIIssorIknN8f98aOMcuQ5M6d5byeZ57M3Lkzc24C98xnuecjqooxxpjYdZnfARhjjPGXJQJjjIlxlgiMMSbGWSIwxpgYZ4nAGGNinCUCY4yJcZYIjDGZEpGPROTRIPdVEanqdUzGG5YITL4RkT0i8qOInBGRwyIyT0SuyrBPIxH5UES+E5FTIvKuiCRl2KeoiEwSkX3ue33lPi4Z2iPyjojcLCIHsnhunoicd4/9WxF5X0RqZPNew90Tcf8M2/u724fnc/gmylgiMPmtnapeBdwA3AgMSX9CRBoC/wTeAcoAlYDPgFUiUtnd53LgA6AWcBtQFGgIHAfqexW0iMR79d65NNb9PZYFDgIv57D/DuDBDNsecrcbky1LBMYTqnoYWIGTENKNBV5R1RdU9TtV/VZVnwZWA8PdfR4EKgAdVXWbql5U1SOq+mdVXZ7ZZ4lILfdb87ci8o2IPOVunyciIwP2+9m3cLcF8ycR2Qx8795/K8N7vyAik937xUTkZRE5JCIHRWSkiMTl8VeVLVX9EVjMz3+PmVkLFBaRWm6stYBC7vafiEh3EUlxf1fLRKRMwHO3iMiXbkvtRUAyvPYREflCRE6IyAoRqZgPh2jCgCUC4wkRKQe0BVLcx4WBRsCbmey+GLjFvd8aeE9VzwT5OUWAfwHv4bQyquK0KIJ1P3AHcDXwBnC7+564J/l7gYXuvvOAVPczbgTaAEH1oeeWiFzpxpgSxO4L+F+r4CH3ceB7tQT+inNMpYG9OMeM2+22BHgaKAl8BTQOeG0H4Cngd0Ap4L/A67k8LBNmLBGY/PY3EfkO2A8cAZ51txfH+fd2KJPXHMI5+QCUyGKfrNwJHFbV8ap61m1prLmE109W1f2q+qOq7gU2AB3d51oCP6jqahG5DrgdeFxVv1fVI8BEoNMlfNalGCQiJ4HvgCZA1yBe8ypwv4gUcON6NcPzXYA5qrpBVc/hdNs1FJEEnGPbqqpvqeoFYBJwOOC1vYC/quoXqpoKjAJusFZBdLBEYPLbXapaBLgZqMH/TvAngIs430QzKg0cc+8fz2KfrJTH+faaW/szPF6I8w0coDP/aw1UBAoAh0TkpHuSnglcm9mbugO96bcKuYhrnKpeDSQAPwLVc3qBqu7DaTmMAnaqasZjK4PTCkjf/wzO77us+9z+gOeUn/9uKgIvBBz7tzhdR2Uv+chM2LFEYDyhqv/B6UoZ5z7+HvgEuCeT3e/lf905/wJudbtEgrEfqJzFc98DhQMe/yqzUDM8fhO42e3a6sj/EsF+4BxQUlWvdm9FVbVWZh+sqlcF3PYFeSyZvc8+oD/OSfiKIF7yCjDQ/ZnR1zgndOCnbqcSOIPRh3CSavpzEvgY5/h7Bhz71ap6hap+fKnHZMKPJQLjpUnALSLya/fxYOAhEfmDiBQRkWvcwdyGwHPuPgtwTjpvi0gNEblMREqIyFMicnsmn/F3oLSIPC4iBd33beA+twmnz7+4iPwKeDyngFX1KPARMBfYrapfuNsP4cx4Gu9Ob71MRKqISPNc/F5+IiKFMtwk4z6q+j7OSbxHEG+5CGfsYnEmz70OPCwiN4hIQZyWwxpV3QP8A6glIr9zZ1D9gZ8nzhnAkIDB6GIikllSNxHIEoHxjHtSfQUY5j7+f8CtOAOOh3C6KW4EmqjqTnefczgDxl8C7wOngU9xuph+0fevqt/hDDS3w+nT3gm0cJ9egDM9dQ/OSXxRkKEvdGNYmGH7g8DlwDacrq63uLRurIzK4nT7BN6qZLHv88CT7gk8S+5Yx7/c2UYZn/sX8AzwNs7vvwruGIeqHsNprY3G6S5KBFYFvHYpMAZ4Q0ROA1twJgOYKCC2MI0xxsQ2axEYY0yMs0RgjDExzhKBMcbEOEsExhgT48Kt0FaOSpYsqQkJCX6HYYwxEWX9+vXHVLVUZs9FXCJISEhg3bp1fodhjDERRUT2ZvWcdQ0ZY0yMs0RgjDExzhKBMcbEuIgbI8jMhQsXOHDgAGfPnvU7lEtWqFAhypUrR4ECBfwOxRgTo6IiERw4cIAiRYqQkJBAJjW7wpaqcvz4cQ4cOEClSpX8DscYE6M86xoSkTkickREtmTxvIjIZHfZvM0iUje3n3X27FlKlCgRUUkAQEQoUaJERLZkjDHRw8sxgnk4i49npS1OhcNEnPK60/PyYZGWBNJFatzGmOjhWSJQ1ZU4qxhlpQPOQuaqqquBq0UkLyV9jTEmKs397046vPBvnnt3qyfv7+cYQVl+vhTeAXfbL9arFZEeuItyVKiQm1X/vHfVVVdx5szP11sfPnw4s2fPplSpUpw/f55nnnmG+++/P4t3MMZEsoVr9vHOpoP5/r4nT55k+4mLANxYyZtlAyJisFhVZwGzAOrVqxdRCyg88cQTDBo0iJ07d3LTTTfx+9//3mYIGROG8noiX7Pb6QBpUKl4vsSTmprKrl27OHToEFdccQUP3VyL4e1r58t7Z+RnIjjIz9dELedui0qJiYkULlyYEydOcO21ma53bozxUE4n+ryeyBtUKk6HG8rSuUHeey3S0tK4/vrr2b59O4MGDWL48P5ccUUwS1bnjp+JYBnQV0TeABoAp9x1YfPkuXe3su3r03kOLlBSmaI82y7TNcqDtmHDBhITEy0JGBMiGU/8OZ3o8/NEnlvHjx+nePHixMXF8Ze//IXy5ctTr149zz/Xs0QgIq8DNwMlReQA8CxQAEBVZwDLgduBFOAH4GGvYvHTxIkTmTt3Ljt27ODdd9/1OxxjolJm3/YznvjD4USfFVXltddeo3///owePZru3bvTsWPHkH2+Z4lAVbMdFVVnseTH8vtz8/rNPb+ljxEsW7aM5ORkvvrqKwoVKuR3WMZEvMCTf2bf9sP5xB9o//799OrVi+XLl/Pb3/6Wxo0bhzyGiBgsjgbt27fn5ZdfZv78+fTs2dPvcIyJCNn16wee/CPlpJ/R66+/Ts+ePUlLS2PSpEn07duXuLi4kMdhiSCf/PDDD5QrV+6nxwMGDPjFPsOGDaNz5850796dyy6zen/GBAqmeydQpJ78A11zzTU0aNCAWbNm+VpmxhJBPrl48WKO+9x0001s3749BNEYExmipXsnWKmpqUycOJHz588zdOhQbrvtNm699VbfKwxYIjDGhFRWJ/9oO+ln9Nlnn5GcnMz69eu59957UVVExPckAJYIjDEey24aZ7Sf/AHOnTvHyJEjGT16NMWLF+fNN9/k7rvvDosEkC5qEkF6do00zuQpY6JDpE/j9MLOnTsZM2YMnTt3ZsKECZQoUcLvkH4hKhJBoUKFOH78eMSVok5fj8Cmk5pIk9Vsnljo5w/GmTNneOedd+jSpQu1a9fmyy+/pHLlyn6HlaWoSATlypXjwIEDHD161O9QLln6CmXGhKtLmc0Tiyf9jN5//3169OjB3r17qVu3LjVr1gzrJABRkggKFChgK3wZk49ibTZPfjhx4gSDBg1izpw5VKtWjf/85z/UrFnT77CCEhWJwBiTN7E+oJtXaWlpNG7cmB07djBkyBCGDRsWUV2+lgiMiUE5FWSzk39wjh079lORuFGjRlGhQgXq1s31qru+sURgTAxJTwB24s8bVWXBggU8/vjjjB49mh49enDXXXf5HVauWSIwJopl983fTvy5s3fvXnr27MmKFSto1KgRzZo18zukPLNEYEwUsm/+3nj11Vfp3bs3qsqUKVPo06dPVNQNs0RgTBSwb/6hUapUKRo3bszMmTOpWLGi3+HkG4m0K1vr1aun69at8zsMY3wVzOpblgDy7sKFC4wfP54LFy7wzDPPAJFbxUBE1qtqpsudWYvAmAizcM0+nlr6OWBdPl7auHEjycnJbNy4kU6dOoVVkbj8ZonAmAiQ2QVeozpebyd+D5w9e5YRI0YwduxYSpYsydtvv83vfvc7v8PylCUCY8JYZoO+9u3fWykpKYwbN44HH3yQ8ePHc8011/gdkucsERgTRmzQ1x9nzpxh6dKldO3aldq1a7N9+/aYKltjicAYn1jJ5vCwYsUKevTowf79+6lXrx41a9aMqSQAlgiMCbms5vin37cTf2gcP36cAQMG8Morr1CjRg3++9//RkyRuPxmicCYEMiqmqed9P2RXiQuJSWFoUOH8vTTT0dUkbj8ZonAGA9YNc/wdPToUUqUKEFcXBxjxoyhYsWK3HDDDX6H5TtLBMbkk+xq+NvJ31+qyrx58xgwYACjR4+mZ8+edOjQwe+wwoYlAmPyyKZ4hrc9e/bQo0cP3n//fZo2bUqLFi38DinsWCIwJg8yXuVrJ//wsmDBAnr37o2IMG3aNHr27BkVReLymyUCY3IhYyvArvINT9dddx3NmjVjxowZVKhgf5+sWCIwJgh2oVdkuHDhAmPHjiUtLY1hw4bRpk0b2rRp43dYYc8SgTE5sCJvkWHDhg088sgjfPbZZ3Tu3Dliq4T6wRKBMdkITALW/ROefvzxR5577jnGjRtHqVKlWLp0aUQvG+kHTxOBiNwGvADEAS+p6ugMz1cA5gNXu/sMVtXlXsZkTE6s0mdk2bVrFxMmTKBbt248//zzMVEkLr95lghEJA6YCtwCHADWisgyVd0WsNvTwGJVnS4iScByIMGrmIzJScZuIOsCCk+nT59myZIldOvWjVq1arFz586oWjEs1LxsEdQHUlR1F4CIvAF0AAITgQJF3fvFgK89jMeYLNksoMixfPlyevXqxcGDB2nQoAE1a9a0JJBHXk6oLQvsD3h8wN0WaDjwgIgcwGkN9MvsjUSkh4isE5F1R48e9SJWE8PSWwFrdn9Lg0rFLQmEqWPHjtG1a1fuuOMOihQpwqpVq2K2SFx+83uw+H5gnqqOF5GGwAIRqa2qFwN3UtVZwCxw1iz2IU4TpWwwODKkF4nbtWsXw4YN46mnnqJgwYJ+hxU1vEwEB4HyAY/LudsCJQO3AajqJyJSCCgJHPEwLmOsKyhCfPPNN5QqVYq4uDjGjRtHxYoVqVOnjt9hRR0vE8FaIFFEKuEkgE5A5wz77ANaAfNEpCZQCLC+H5Pv7IKwyKKqzJkzh4EDBzJ69Gh69epFu3bt/A4ranmWCFQ1VUT6AitwpobOUdWtIjICWKeqy4CBwGwReQJn4LibqlrXj8lXdkFYZNm1axfdu3fnww8/pHnz5rRu3drvkKKep2ME7jUByzNsGxZwfxvQ2MsYTGyzMYDIMn/+fPr06UNcXBwzZsyge/fuViQuBPweLDbGEzYGEJnKlClDy5YtmT59OuXKlfM7nJhhicBElczWBrAuoPB1/vx5Ro8ezcWLFxk+fDi33HILt9xyi99hxRxLBCZiZRwABhsEjiRr167lkUceYcuWLXTt2tWKxPnIEoGJKNktB5l+3xJAePvhhx8YNmwYEydOpHTp0ixbtsxmBPnMEoGJKO9sOsi2Q6dJKl3UTvoRavfu3UyZMoXu3bszZswYihUr5ndIMc8SgQlbmXX9pCeBRT0b+hSVyY1Tp06xZMkSHn74YWrVqkVKSgrly5fP+YUmJCwRmLCSU9dPUumidLghY8kqE87+8Y9/0LNnTw4dOkTDhg2pUaOGJYEwY4nAhIXMZvtY109kO3r0KI8//jgLFy6kdu3aLFmyhBo1avgdlsmEJQLjK5vuGZ3S0tJo0qQJu3fv5rnnnmPw4MFcfvnlfodlsmCJwPgmY+kHSwCR7/Dhw1x77bXExcUxfvx4EhISqF27tt9hmRzYtdvGFxlLPyzq2dCSQAS7ePEiM2fOpFq1asycOROAO++805JAhAiqRSAiVwAVVHW7x/GYKGZrAUenlJQUunfvzkcffUTLli259dZb/Q7JXKIcE4GItAPGAZcDlUTkBmCEqrb3OjgT+bKaBWRdQdFh7ty59OnTh8svv5zZs2eTnJxsVwdHoGBaBMNx1h/+CEBVN7lrDBiTJZsFFBsqVKjArbfeytSpUylb1qb1RqpgEsEFVT2VIcvbmgHmZ2zhl9hw7tw5/vrXv3Lx4kVGjBhBq1ataNWqld9hmTwKJhFsFZHOQJyIJAJ/AD72NiwTCbK7+MsSQPRZs2YNycnJbN26lYceesiKxEWRYBJBP2AocA5YiLPi2J+9DMqEv4xTP+3EH72+//57nnnmGSZNmkTZsmX5+9//zh133OF3WCYfBZMI7lDVoTjJAAARuQd407OoTNhLbwnYrJ/ot3fvXqZNm0avXr0YPXo0RYsW9Tskk8+CuY5gSJDbTIxYuGYfa3Z/S4NKxS0JRKmTJ0/y0ksvAZCUlERKSgrTpk2zJBClsmwRiEhb4HagrIhMDniqKJDqdWAmvGQ2HmDF36LTO++8Q+/evTly5AhNmjShRo0atmxklMuuRfA1sA44C6wPuC0D7IqRGJI+HhA4IGxdQtHnyJEjdOrUibvuuotSpUqxevVqKxIXI7JsEajqZ8BnIrJQVS+EMCYTRjKWgrCTf3RKS0ujcePG7Nu3j5EjR/Lkk09SoEABv8MyIRLMYHGCiPwVSAIKpW9U1cqeRWV8ZaUgYsfXX3/Nr371K+Li4njhhRdISEggKSnJ77BMiAUzWDwXmI4zLtACeAV41cugjD8WrtnHfTM/sW6gGHDx4kWmT59OjRo1mDFjBgC33367JYEYFUyL4ApV/UBERFX3AsNFZD0wzOPYTIjYmgCxZceOHXTv3p2VK1fSunVr2rZt63dIxmfBJIJzInIZsFNE+gIHgau8DcuEgiWA2PPyyy/Tt29fChUqxJw5c+jWrZtdHWyCSgT9gcI4pSX+jNM99JCXQRlvWQKIXQkJCbRt25apU6dSunRpv8MxYUJUs64fJyJxwBhVHRS6kLJXr149Xbdund9hRCRLALHn3Llz/PnPTkWYkSNH+hyN8ZOIrFfVepk9l22LQFXTRKSJN2EZr1lF0Nj28ccfk5yczJdffskjjzxiReJMloLpGtooIstwagt9n75RVZd4FpXJk8y++af/tAQQ/c6cOcPQoUOZMmUK5cuX57333rNVw0y2gkkEhYDjQMuAbQrkmAhE5DbgBSAOeElVR2eyz704i98o8Jmqdg4iJpMJ6/oxAPv27WPmzJk89thjjBo1iiJFivgdkglzOSYCVX04N2/sji9MBW4BDgBrRWSZqm4L2CcRp4BdY1U9ISLX5uazYp0lAHPixAnefPNNevToQVJSErt27aJMmTJ+h2UiRFCL1+dSfSBFVXcBiMgbQAdgW8A+3YGpqnoCQFWPeBhPVMq4LoAlgNizdOlS+vTpw9GjR2nevDnVq1e3JGAuSTBXFudWWWB/wOMD7rZA1YBqIrJKRFa7XUm/ICI9RGSdiKw7evSoR+FGpsB1ARb1bGhJIIYcPnyYe+65h9/97nf86le/4tNPP6V69ep+h2UikJctgmA/PxG4GSgHrBSR61X1ZOBOqjoLmAXO9NFQBxmubF2A2JWWlkbTpk3Zv38/o0aNYtCgQVYkzuRajolARK4DRgFlVLWtiCQBDVX15RxeehAoH/C4nLst0AFgjVvddLeI7MBJDGuDPYBYlt4asHUBYseBAwcoU6YMcXFxTJ48mUqVKlmpaJNnwXQNzcNZpzi903EH8HgQr1sLJIpIJRG5HOiEs5ZBoL/htAYQkZI4XUW7gnjvmJZeHG7bodPWGogRFy9eZMqUKdSoUYPp06cD0LZtW0sCJl8EkwhKqupi4CKAqqYCaTm9yN2vL04S+QJYrKpbRWSEiLR3d1sBHBeRbcC/gT+q6vFcHEdMeWfTQbYdOk1S6aLWGogBX375Jc2aNeMPf/gDTZo04c477/Q7JBNlghkj+F5ESuDM80dEfgucCubNVXU5sDzDtmEB9xUY4N5MDtKniaYngUU9G/odkvHYSy+9RN++fSlcuDDz58+na9eudnWwyXfBJIKBOF06VURkFVAK+L2nUZmfyeo6ARP9qlSpQrt27XjxxRe57rrr/A7HRKlsi879tJNIPFAdEGC7n0tXxlrRObtOILacPXuWESNGADBq1CifozHRJNdF59wXbwbeABap6lf5HZzJmq0XHFtWrVpFcnIy27dv59FHH7UicSZkghksboezTOViEVkrIoNExM5IHgpcMhIsCUS77777jn79+tG0aVPOnTvHihUrmD17tiUBEzI5JgJV3auqY1X1JqAzUAfY7XlkMSq9FZB+oZglgeh34MABXnrpJfr168fnn39OmzZt/A7JxJigriwWkYrAfe4tDXjSy6BiWWDJCEsA0ev48eMsXryY3r17U7NmTXbt2mUrhhnfBDNGsAYogLMewT3pReRM/rOSEdFPVXn77bd57LHH+Pbbb2nZsiXVq1e3JGB8FUyL4EFV3e55JDEs4/RQmxoanQ4dOsRjjz3G0qVLuemmm/jnP/9pReJMWMgyEYjIA6r6KnCHiNyR8XlVneBpZDHCpofGhvQicQcPHmTs2LE88cQTxMf7XfPRGEd2/xKvdH9mtryRVQDNBzY9NPrt37+fsmXLEhcXx9SpU6lUqRLVqlXzOyxjfibLRKCqM927/1LVVYHPiUhjT6OKchm7giwJRJ+0tDSmTp3KkCFDGDt2LI899pitG2zCVjBt0ylA3SC2mSCl1wuyrqDo9MUXX5CcnMwnn3xC27Ztadeund8hGZOt7MYIGgKNgFIiElgUrijOYvQmFwJnBlnRuOgza9Ys+vXrR5EiRViwYAFdunSxC8NM2MuuRXA5cJW7T+A4wWms6FyuBI4J2Myg6JSYmEjHjh2ZPHky1157rd/hGBOUHIvOiUhFVd0bonhyFKlF52xgODr9+OOPDB8+HBFh9OjRfodjTJZyVXRORCap6uPAiyLyi2yhqu0zeZnJgl0xHH1WrlzJo48+ys6dO+nVq5cViTMRK7uuoQXuz3GhCCSa2RXD0eX06dMMHjyY6dOnU7lyZT744ANatmzpd1jG5Fp200fXuz//k75NRK4Byqvq5hDEFjVskfno8vXXXzNv3jwGDBjAiBEjuPLKK3N+kTFhLJhaQx8B7d191wNHRGSVqtrykkGw1kB0OHbsGIsXL6ZPnz7UqFGD3bt324phJmoEcx1BMVU9LSKPAq+o6rPuYjUmG1Y/KDqoKosXL6Zfv36cPHmS1q1bU61aNUsCJqoEszBNvIiUBu4F/u5xPFHB1hSIDl9//TV33XUXnTp1omLFiqxfv97KQ5ioFEyLYASwAlilqmtFpDKw09uwIk96CwCw0hFRIC0tjWbNmnHw4EHGjRtH//79rUiciVo5/stW1Tdx1iJIf7wLuNvLoCJRetmIpNJFrXREBNu7dy/lypUjLi6OadOmUblyZapWrep3WMZ4KseuIREpJyJLReSIe3tbRMqFIrhIkT4gnFS6KIt6NmRRz4aWBCJMWloaEyZMoGbNmkyfPh2ANm3aWBIwMSGYMYK5wDKgjHt7191mXDY9NLJt2bKFRo0aMXDgQFq1asVdd93ld0jGhFQwiaCUqs5V1VT3Ng8o5XFcEcOmh0a2GTNmULduXXbt2sXChQtZtmwZ5cpZg9fElmASwXEReUBE4tzbA8BxrwOLFNYaiEzpNbZq1qzJPffcw7Zt27j//vutRISJScFMg3gEZ/2Bie7jVcDDnkUUQaw1EHl++OEHhg0bRlxcHGPGjKF58+Y0b97c77CM8VWOLQJV3auq7VW1lHu7S1X3hSK4cGYlpSPPRx99RJ06dRg/fjxnzpwhp8q7xsSKYGYNVRaRd0XkqDtr6B33WoKYZtVEI8epU6fo2bMnLVq0AODDDz9k6tSp1g1kjCuYMYKFwGKgNM6soTeB170MKtxZl1BkOXToEK+++iqDBg1i8+bNPyUEY4wjmERQWFUXBMwaehUoFMybi8htIrJdRFJEZHA2+90tIioimS6aEG5sgDj8HT16lClTpgBQo0YN9uzZw/PPP0/hwoV9jsyY8BNMIvg/ERksIgkiUlFEngSWi0hxESme1YtEJA6YCrQFkoD7RSQpk/2KAP2BNbk7BH9YayA8qSoLFy6kZs2aDBw4kB07dgBQqpTNeDYmK8EkgnuBnsC/gY+A3kAnnJLU2a0ZWR9IUdVdqnoeeAPokMl+fwbGAGeDD9s/6d1CJvzs37+fdu3a0aVLF6pWrcrGjRutSJwxQQim1lClXL53WWB/wOMDQIPAHUSkLs5CN/8QkT9m9UYi0gPoAVChgn/fwm2mUPhKTU3l5ptv5vDhw0ycOJF+/foRFxfnd1jGRATfyimKyGXABKBbTvuq6ixgFjiL13sbWdZsplD42bNnD+XLlyc+Pp6ZM2dSuXJlKleO+UltxlySYLqGcusgUD7gcTl3W7oiQG3gIxHZA/wWWBauA8Y2Uyi8pKamMm7cOGrWrMm0adMAaN26tSUBY3LByxbBWiBRRCrhJIBOQOf0J1X1FFAy/bG7JOYgVc1u3MEX1iUUXjZv3kxycjLr1q2jQ4cO3H23VUU3Ji+CuaBM3FpDw9zHFUSkfk6vU9VUoC/OojZfAItVdauIjBCR9nkNPFQCk4B1Cflv2rRp3HTTTezdu5dFixaxdOlSypQp43dYxkS0YFoE04CLQEuc1cq+A94GfpPTC1V1ObA8w7ZhWex7cxCxhJyNC4QHVUVEqF27Np06dWLixImULFky5xcaY3IUTCJooKp1RWQjgKqeEJHLPY4rLNi4gP++//57nn76aeLj43n++edp1qwZzZo18zssY6JKMIPFF9yLwxRARErhtBCimo0L+O+DDz7g+uuvZ9KkSZw7d86KxBnjkWASwWRgKXCtiPwF+H/AKE+jCgPWJeSfkydP8uijj9K6dWvi4+NZuXIlkydPtiJxxngkmAvKXhOR9UArQIC7VPULzyPzkXUJ+cVeShAAABLQSURBVOubb77hjTfe4E9/+hPPPvssV1xxhd8hGRPVckwEIlIB+AFnreKftkXzmgRWVC700k/+/fv3p3r16uzZs8cGg40JkWAGi/+BMz4gOFVHKwHbgVoexuUbaw2Elqry2muv0b9/f86cOcPtt99OYmKiJQFjQiiYFcquV9U67s9EnGJyn3gfmj+sNRA6+/bt44477qBr165Ur16dTZs2kZiY6HdYxsScS76yWFU3iEiDnPeMXNYa8F56kbgjR44wefJk+vTpY0XijPFJMGMEAwIeXgbUBb72LCIT1Xbt2kXFihWJj49n9uzZVKlShYSEBL/DMiamBTN9tEjArSDOmEFm6woYk6XU1FTGjBlDUlISU6dOBaBVq1aWBIwJA9m2CNwLyYqo6qAQxWOi0KZNm0hOTmbDhg107NiRe+65x++QjDEBsmwRiEi8qqYBjUMYj69s9bH89+KLL/Kb3/yGgwcP8tZbb7FkyRJKly7td1jGmADZtQg+xRkP2CQiy4A3ge/Tn1TVJR7HFnI2Yyj/pBeJq1OnDl26dGHChAkUL57lEtfGGB8FM2uoEHAcp/po+vUECkRdIgCbMZRXZ86cYejQoRQoUIBx48ZZkThjIkB2g8XXujOGtgCfuz+3uj+3hCA2E2H++c9/Urt2baZMmcKFCxesSJwxESK7FkEccBVOCyAj+x9ufnLixAkGDBjAvHnzqF69OitXrqRJkyZ+h2WMCVJ2ieCQqo4IWSQ+CywtYS7NkSNHeOuttxgyZAjDhg2jUKFCfodkjLkE2SWCmKn5a2sPXLrDhw/z+uuv88QTT/xUJK5EiRJ+h2WMyYXsxghahSwKn9naA8FTVebPn09SUhJDhgxh586dAJYEjIlgWSYCVY2pCfU2Wyhne/bs4bbbbqNbt24kJSVZkThjokQwJSaiml1EFpzU1FRatGjBxx9/zNSpU1m5ciU1atTwOyxjTD645Oqj0cTGBnKWkpJCpUqViI+PZ86cOVSuXJmKFSv6HZYxJh/FdIvAxgayduHCBUaNGkWtWrV+KhLXokULSwLGRKGYbhGAjQ1kZsOGDSQnJ7Np0ybuuece7rvvPr9DMsZ4KGZbBDY2kLnJkydTv359Dh8+zJIlS1i8eDHXXXed32EZYzwUs4nACsz9XHo5iBtvvJEHH3yQbdu20bFjR5+jMsaEQkx3DVm3EHz33XcMGTKEggULMn78eJo2bUrTpk39DssYE0Ix2yIw8N5771G7dm2mTZuGqlqROGNilCWCGHT8+HEeeugh2rZty5VXXsmqVauYMGECIjFTVcQYE8ASQQw6fvw4S5cu5ZlnnmHjxo00bNjQ75CMMT7yNBGIyG0isl1EUkRkcCbPDxCRbSKyWUQ+EJGQTFKPxRlDhw4dYty4cagq1apVY+/evYwYMYKCBQv6HZoxxmeeJQJ34fupQFsgCbhfRJIy7LYRqKeqdYC3gLFexRMolmYMqSpz5syhZs2aPPPMM6SkpABwzTXX+ByZMSZceNkiqA+kqOouVT0PvAF0CNxBVf+tqj+4D1cD5TyM52diYcbQ7t27adOmDcnJyfz617/ms88+syJxxphf8HL6aFlgf8DjA0CDbPZPBv4vsydEpAfQA6BCheg+eeeX1NRUWrZsyfHjx5k+fTo9evTgsstsSMgY80thcR2BiDwA1AOaZ/a8qs4CZgHUq1fP5jhmY+fOnVSuXJn4+Hjmzp1LlSpVKF++vN9hGWPCmJdfEQ8CgWegcu62nxGR1sBQoL2qnvMwnqh24cIFRo4cSe3atXnxxRcBuPnmmy0JGGNy5GWLYC2QKCKVcBJAJ6Bz4A4iciMwE7hNVY94GEtUW7duHcnJyWzevJlOnTpx//33+x2SMSaCeNYiUNVUoC+wAvgCWKyqW0VkhIi0d3d7HrgKeFNENonIMq/iiVYvvPACDRo04NixY7zzzju8/vrrXHvttX6HZYyJIJ6OEajqcmB5hm3DAu639vLzo5mqIiLUq1eP5ORkxo4dy9VXX+13WMaYCBQWg8UmeKdPn+ZPf/oThQoVYuLEiTRu3JjGjRv7HZYxJoLZfMIIsnz5cmrVqsWsWbOIj4+3InHGmHwRc4kgEstLHDt2jAceeIA77riDYsWK8fHHH/P8889bkThjTL6IuUQQieUlTpw4wbvvvsuzzz7Lhg0baNAgu+vyjDHm0sTkGEEklJc4ePAgr732Gn/84x9JTExk7969NhhsjPFEzLUIwp2qMnv2bJKSkhg+fDhfffUVgCUBY4xnLBGEka+++opWrVrRo0cP6taty+bNm6latarfYRljolxMdg2Fo9TUVFq1asW3337LzJkzefTRR61InDEmJCwR+Gz79u1UqVKF+Ph45s+fT5UqVShXLmTVuI0xxrqG/HL+/Hmee+45rr/+eqZOnQpA8+bNLQkYY0LOWgQ++PTTT0lOTmbLli107tyZLl26+B2SMSaGWYsgxCZNmkTDhg1/ujbgtddeo2TJkn6HZYyJYZYIQiS9HET9+vXp3r07W7du5c477/Q5KmOMsa4hz506dYonn3ySK664gkmTJtGoUSMaNWrkd1jGGPMTaxF46N133yUpKYmXXnqJggULWpE4Y0xYskTggaNHj9K5c2fat29PiRIlWL16NWPGjLEiccaYsGSJwAOnTp1i+fLlPPfcc6xbt47f/OY3fodkjDFZsjGCfLJ//35effVVBg8eTNWqVdm7dy/FihXzOyxjjMlRTLUIvFiL4OLFi8yYMYNatWoxcuTIn4rEWRIwxkSKmEoE+b0Wwc6dO2nZsiW9e/emfv36fP7551YkzhgTcWKuayi/1iJITU3llltu4eTJk7z88ss8/PDDNhhsjIlIMZcI8uqLL74gMTGR+Ph4FixYQJUqVShTpozfYRljTK7FVNdQXpw7d45nn32WOnXq8OKLLwLQtGlTSwLGmIhnLYIgrF69muTkZLZt20bXrl3p2rWr3yEZY0y+sRZBDsaPH0+jRo347rvvWL58Oa+88golSpTwOyxjjMk3lgiycPHiRQAaNmxIr1692LJlC23btvU5KmOMyX/WNZTByZMnGThwIIULF2bKlClWJM4YE/WsRRDgb3/7G0lJScyfP58iRYpYkThjTEywRAAcOXKEe++9l44dO3Ldddfx6aefMmrUKLsuwBgTEywRAKdPn+b999/nL3/5C59++il169b1OyRjjAmZmB0j2LdvHwsWLOCpp56iatWq7Nu3jyJFivgdljHGhJynLQIRuU1EtotIiogMzuT5giKyyH1+jYgkeBVLYMG5adOmUatWLUaNGvVTkThLAsaYWOVZIhCROGAq0BZIAu4XkaQMuyUDJ1S1KjARGONVPOkF53b+ayGPPfYYDRs2ZOvWrVYkzhgT87xsEdQHUlR1l6qeB94AOmTYpwMw373/FtBKPBqhVVU4soPd/3qVuXPnsmLFChISErz4KGOMiShejhGUBfYHPD4ANMhqH1VNFZFTQAngWOBOItID6AFQoULuKofWKluMaxrUZvhftlG6dOlcvYcxxkSjiBgsVtVZwCyAevXq5Wpy/7PtagG18jMsY4yJCl52DR0Eygc8Luduy3QfEYkHigHHPYzJGGNMBl4mgrVAoohUEpHLgU7Asgz7LAMecu//HvhQ7XJeY4wJKc+6htw+/77ACiAOmKOqW0VkBLBOVZcBLwMLRCQF+BYnWRhjjAkhT8cIVHU5sDzDtmEB988C93gZgzHGmOxZiQljjIlxlgiMMSbGWSIwxpgYZ4nAGGNinETabE0ROQrszeXLS5LhquUYYMccG+yYY0NejrmiqpbK7ImISwR5ISLrVLWe33GEkh1zbLBjjg1eHbN1DRljTIyzRGCMMTEu1hLBLL8D8IEdc2ywY44NnhxzTI0RGGOM+aVYaxEYY4zJwBKBMcbEuKhMBCJym4hsF5EUERmcyfMFRWSR+/waEUkIfZT5K4hjHiAi20Rks4h8ICIV/YgzP+V0zAH73S0iKiIRP9UwmGMWkXvdv/VWEVkY6hjzWxD/tiuIyL9FZKP77/t2P+LMLyIyR0SOiMiWLJ4XEZns/j42i0jdPH+oqkbVDafk9VdAZeBy4DMgKcM+fYAZ7v1OwCK/4w7BMbcACrv3e8fCMbv7FQFWAquBen7HHYK/cyKwEbjGfXyt33GH4JhnAb3d+0nAHr/jzuMxNwPqAluyeP524P8AAX4LrMnrZ0Zji6A+kKKqu1T1PPAG0CHDPh2A+e79t4BWIiIhjDG/5XjMqvpvVf3BfbgaZ8W4SBbM3xngz8AY4Gwog/NIMMfcHZiqqicAVPVIiGPMb8EcswJF3fvFgK9DGF++U9WVOOuzZKUD8Io6VgNXi0ieFmKPxkRQFtgf8PiAuy3TfVQ1FTgFlAhJdN4I5pgDJeN8o4hkOR6z22Qur6r/CGVgHgrm71wNqCYiq0RktYjcFrLovBHMMQ8HHhCRAzjrn/QLTWi+udT/7zmKiMXrTf4RkQeAekBzv2PxkohcBkwAuvkcSqjF43QP3YzT6lspIter6klfo/LW/cA8VR0vIg1xVj2sraoX/Q4sUkRji+AgUD7gcTl3W6b7iEg8TnPyeEii80Ywx4yItAaGAu1V9VyIYvNKTsdcBKgNfCQie3D6UpdF+IBxMH/nA8AyVb2gqruBHTiJIVIFc8zJwGIAVf0EKIRTnC1aBfX//VJEYyJYCySKSCURuRxnMHhZhn2WAQ+5938PfKjuKEyEyvGYReRGYCZOEoj0fmPI4ZhV9ZSqllTVBFVNwBkXaa+q6/wJN18E82/7bzitAUSkJE5X0a5QBpnPgjnmfUArABGpiZMIjoY0ytBaBjzozh76LXBKVQ/l5Q2jrmtIVVNFpC+wAmfGwRxV3SoiI4B1qroMeBmn+ZiCMyjTyb+I8y7IY34euAp40x0X36eq7X0LOo+CPOaoEuQxrwDaiMg2IA34o6pGbGs3yGMeCMwWkSdwBo67RfIXOxF5HSeZl3THPZ4FCgCo6gyccZDbgRTgB+DhPH9mBP++jDHG5INo7BoyxhhzCSwRGGNMjLNEYIwxMc4SgTHGxDhLBMYYE+MsEZiwJSJpIrIp4JaQzb5nQhdZ1kSkjIi85d6/IbASpoi0z65KqgexJIhI51B9nolcNn3UhC0ROaOqV+X3vqEiIt1wKp729fAz4t16WZk9dzMwSFXv9OrzTXSwFoGJGCJylbuWwgYR+VxEflFtVERKi8hKtwWxRUSautvbiMgn7mvfFJFfJA0R+UhEXgh4bX13e3ER+Ztb+321iNRxtzcPaK1sFJEi7rfwLe5VsCOA+9zn7xORbiLyoogUE5G9bj0kRORKEdkvIgVEpIqIvCci60XkvyJSI5M4h4vIAhFZhXNhZIK77wb31sjddTTQ1P38J0QkTkSeF5G17rH0zKc/jYl0ftfetpvdsrrhXBm7yb0txbkSvqj7XEmcKyvTW7Vn3J8DgaHu/TicmkMlcdYkuNLd/idgWCaf9xEw273fDLcePDAFeNa93xLY5N5/F2js3r/KjS8h4HXdgBcD3v+nx8A7QAv3/n3AS+79D4BE934DnPInGeMcDqwHrnAfFwYKufcTca64Befq1L8HvK4H8LR7vyCwDqjk99/Zbv7foq7EhIkqP6rqDekPRKQAMEpEmgEXcUrvXgccDnjNWmCOu+/fVHWTiDTHWbBklVte43Lgkyw+83VwasKLSFERuRpoAtztbv9QREqISFFgFTBBRF4DlqjqAQl+WYtFOAng3zglTqa5rZRG/K8MCDgn7MwsU9Uf3fsFgBdF5Aac5Fkti9e0AeqIyO/dx8VwEsfuYIM20ckSgYkkXYBSwE2qekGcqqKFAndwT+DNgDuAeSIyATgBvK+q9wfxGRkHzbIcRFPV0SLyD5y6L6tE5FaCXwBnGU5SKw7cBHwIXAmcDEx+2fg+4P4TwDfAr3G6e7OKQYB+qroiyBhNjLAxAhNJigFH3CTQAvjFusvirMX8jarOBl7CWfJvNdBYRKq6+1wpIll9a77P3acJTlXHU8B/cZJQ+gDsMVU9LSJVVPVzVR2D0xLJ2J//HU7X1C+o6hn3NS/gdN+kqeppYLeI3ON+lojIr4P8vRxSp/5+V5wuscw+fwXQ220tISLVROTKIN7fRDlrEZhI8hrwroh8jtO//WUm+9wM/FFELgBngAdV9ag7g+d1EUnvankap1Z/RmdFZCNOd8sj7rbhON1Nm3GqPaaXMH/cTUgXga04q74FLhn4b2CwiGwC/prJZy0C3nRjTtcFmC4iT7sxvIGzTm92pgFvi8iDwHv8r7WwGUgTkc+AeThJJwHYIE7f01Hgrhze28QAmz5qjEtEPsKZbhnJaxYYc8msa8gYY2KctQiMMSbGWYvAGGNinCUCY4yJcZYIjDEmxlkiMMaYGGeJwBhjYtz/B+GJAzxo/qniAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c03bfa0a-56d8-4c88-b69b-6d9e4dd4a9de",
        "id": "hUZ7dNt5jqkV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# AUC score\n",
        "metrics.auc(fpr_lr,tpr_lr)"
      ],
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7801340090512356"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcXWFTuRoWfR",
        "colab_type": "text"
      },
      "source": [
        "## Feature selection "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "scrolled": true,
        "id": "mJ0FqgVjBpjB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "af932d99-5fed-4e36-d376-0e0a9dd73e87"
      },
      "source": [
        "# Store the coef for feature selection\n",
        "res = pd.DataFrame(columns=['Feature', 'Coef'])\n",
        "\n",
        "for k,v in sorted(zip(map(lambda x: round(x, 4), best_LR_model.fit(model_train_x, model_train_y).coef_[0]), \\\n",
        "                      model_train_x.columns), key=lambda k_v:(-abs(k_v[0]),k_v[1])):\n",
        "    print (v + \": \" + str(k))\n",
        "    res = res.append({'Feature': v, 'Coef': k}, ignore_index=True)\n"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "reply_t: -1.1049\n",
            "1-10_interactions: -1.0785\n",
            "21-30_interactions*11-15d_stay: 0.9483\n",
            ">30_interactions*>15d_stay: 0.8806\n",
            "21-30_interactions*>450_char_message: 0.8627\n",
            "0_reviews: -0.8603\n",
            "21-30_interactions: 0.7717\n",
            "1-10_interactions*>90d_lead_time: -0.7283\n",
            "21-30_interactions*>15d_stay: -0.5746\n",
            "contact_me*>90d_lead_time: 0.5299\n",
            ">30_interactions: 0.5146\n",
            "past_booker*>30_interactions: 0.509\n",
            "21-30_reviews: 0.5034\n",
            ">30_interactions*>450_char_message: -0.5009\n",
            ">30_reviews: 0.4927\n",
            "1-10_interactions*1-5d_stay: -0.486\n",
            ">30_interactions*151-300_char_message: 0.4131\n",
            "contact_me: 0.4108\n",
            "21-30_interactions*>90d_lead_time: 0.4104\n",
            "contact_me*1-30d_lead_time: -0.4094\n",
            ">30_interactions*11-15d_stay: -0.4076\n",
            "21-30_interactions*0-150_char_message: -0.4035\n",
            "1-10_interactions*301-450_char_message: -0.3606\n",
            "1-10_interactions*151-300_char_message: -0.3539\n",
            "11-20_interactions*>15d_stay: -0.3537\n",
            ">30_interactions*301-450_char_message: 0.3519\n",
            "contact_me*61-90d_lead_time: 0.3509\n",
            "past_booker*1-10_interactions: -0.3465\n",
            ">30_interactions*>90d_lead_time: 0.3236\n",
            "1-10_interactions*6-10d_stay: -0.3114\n",
            "11-20_interactions*1-5d_stay: 0.3087\n",
            "11-20_reviews: 0.3068\n",
            "21-30_interactions*301-450_char_message: 0.2885\n",
            "1-10_reviews: -0.2813\n",
            "31-60d_lead_time: 0.2702\n",
            "1-10_interactions*>450_char_message: -0.2647\n",
            ">30_interactions*0-150_char_message: 0.2505\n",
            "11-20_interactions*>90d_lead_time: -0.2408\n",
            "21-30_interactions*61-90d_lead_time: 0.2381\n",
            ">90d_lead_time: -0.2351\n",
            "11-15d_stay: 0.2331\n",
            "301-450_char_message*11-15d_stay: 0.2243\n",
            "past_booker: 0.2193\n",
            "1_guest: 0.2152\n",
            "151-300_char_message*1-5d_stay: 0.2145\n",
            ">30_interactions*31-60d_lead_time: 0.2067\n",
            "21-30_interactions*6-10d_stay: 0.2056\n",
            "1-10_interactions*11-15d_stay: -0.2039\n",
            "301-450_char_message: 0.1974\n",
            "21-30_interactions*1-5d_stay: 0.1923\n",
            "contact_me*5-6_guests: 0.1826\n",
            "past_booker*11-20_interactions: 0.1791\n",
            ">450_char_message*61-90d_lead_time: 0.1775\n",
            "301-450_char_message*1-30d_lead_time: 0.1659\n",
            "11-20_interactions*0-150_char_message: 0.1627\n",
            "1-10_interactions*31-60d_lead_time: -0.1602\n",
            "5-6_guests: -0.1552\n",
            "151-300_char_message*11-15d_stay: -0.1521\n",
            "contact_me*1_guest: -0.1513\n",
            "0-150_char_message*61-90d_lead_time: -0.1388\n",
            "contact_me*2_guests: 0.1383\n",
            "301-450_char_message*31-60d_lead_time: 0.1368\n",
            ">30_interactions*61-90d_lead_time: -0.1366\n",
            "1-10_interactions*61-90d_lead_time: -0.1287\n",
            "1-30d_lead_time: 0.1286\n",
            ">450_char_message*>90d_lead_time: -0.1262\n",
            ">15d_stay: -0.125\n",
            "contact_me*>6_guests: 0.1234\n",
            "past_booker*21-30_interactions: -0.1222\n",
            ">30_interactions*1-30d_lead_time: 0.1208\n",
            "contact_me*3-4_guests: 0.1178\n",
            "21-30_interactions*31-60d_lead_time: 0.1143\n",
            "11-20_interactions*31-60d_lead_time: 0.1094\n",
            "151-300_char_message*31-60d_lead_time: 0.1074\n",
            "0-150_char_message*6-10d_stay: -0.1065\n",
            "11-20_interactions*11-15d_stay: -0.1037\n",
            "11-20_interactions*6-10d_stay: 0.1022\n",
            "1-10_interactions*0-150_char_message: -0.0994\n",
            "151-300_char_message*>15d_stay: -0.097\n",
            "11-20_interactions*>450_char_message: -0.0905\n",
            "0-150_char_message: -0.0896\n",
            "0-150_char_message*31-60d_lead_time: 0.0877\n",
            "301-450_char_message*1-5d_stay: -0.0863\n",
            ">450_char_message*11-15d_stay: 0.0858\n",
            "11-20_interactions*301-450_char_message: -0.0825\n",
            "151-300_char_message*6-10d_stay: 0.0814\n",
            ">450_char_message*1-5d_stay: -0.0805\n",
            "1-10_interactions*>15d_stay: -0.0772\n",
            "0-150_char_message*11-15d_stay: 0.0751\n",
            "151-300_char_message*>90d_lead_time: -0.0635\n",
            ">450_char_message*31-60d_lead_time: -0.0617\n",
            "1-10_interactions*1-30d_lead_time: -0.0613\n",
            "contact_me*31-60d_lead_time: -0.0607\n",
            "11-20_interactions*1-30d_lead_time: 0.0602\n",
            "301-450_char_message*61-90d_lead_time: -0.0576\n",
            "0-150_char_message*>15d_stay: -0.0489\n",
            "301-450_char_message*>15d_stay: 0.0477\n",
            "301-450_char_message*>90d_lead_time: -0.0477\n",
            "151-300_char_message: 0.0468\n",
            "11-20_interactions: -0.0465\n",
            "contact_me*past_booker: 0.0417\n",
            "0-150_char_message*1-30d_lead_time: -0.0409\n",
            ">6_guests: 0.0404\n",
            "1-5d_stay: 0.0383\n",
            "11-20_interactions*151-300_char_message: -0.0363\n",
            "3-4_guests: 0.0347\n",
            ">450_char_message*6-10d_stay: 0.0282\n",
            ">450_char_message*>15d_stay: -0.0269\n",
            "2_guests: 0.0262\n",
            "11-20_interactions*61-90d_lead_time: 0.0247\n",
            "21-30_interactions*151-300_char_message: 0.0239\n",
            ">30_interactions*1-5d_stay: 0.0233\n",
            ">30_interactions*6-10d_stay: 0.0183\n",
            ">450_char_message*1-30d_lead_time: 0.0171\n",
            "151-300_char_message*61-90d_lead_time: 0.0164\n",
            "6-10d_stay: 0.0149\n",
            "151-300_char_message*1-30d_lead_time: -0.0134\n",
            "301-450_char_message*6-10d_stay: 0.0117\n",
            "0-150_char_message*1-5d_stay: -0.0093\n",
            "21-30_interactions*1-30d_lead_time: 0.0089\n",
            ">450_char_message: 0.0066\n",
            "61-90d_lead_time: -0.0025\n",
            "0-150_char_message*>90d_lead_time: 0.0024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xEXkpduCHqk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "cbf697f9-e578-4a17-ce2b-8546f249b26b"
      },
      "source": [
        "res"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature</th>\n",
              "      <th>Coef</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>reply_t</td>\n",
              "      <td>-1.105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1-10_interactions</td>\n",
              "      <td>-1.079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21-30_interactions*11-15d_stay</td>\n",
              "      <td>0.948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&gt;30_interactions*&gt;15d_stay</td>\n",
              "      <td>0.881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21-30_interactions*&gt;450_char_message</td>\n",
              "      <td>0.863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>0-150_char_message*1-5d_stay</td>\n",
              "      <td>-0.009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>21-30_interactions*1-30d_lead_time</td>\n",
              "      <td>0.009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>&gt;450_char_message</td>\n",
              "      <td>0.007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>61-90d_lead_time</td>\n",
              "      <td>-0.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>0-150_char_message*&gt;90d_lead_time</td>\n",
              "      <td>0.002</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>123 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Feature   Coef\n",
              "0                                 reply_t -1.105\n",
              "1                       1-10_interactions -1.079\n",
              "2          21-30_interactions*11-15d_stay  0.948\n",
              "3              >30_interactions*>15d_stay  0.881\n",
              "4    21-30_interactions*>450_char_message  0.863\n",
              "..                                    ...    ...\n",
              "118          0-150_char_message*1-5d_stay -0.009\n",
              "119    21-30_interactions*1-30d_lead_time  0.009\n",
              "120                     >450_char_message  0.007\n",
              "121                      61-90d_lead_time -0.003\n",
              "122     0-150_char_message*>90d_lead_time  0.002\n",
              "\n",
              "[123 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 248
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ce7s8RLXBsaL",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "res.to_csv('mod2_res.csv')\n",
        "files.download('mod2_res.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G8zPDJtTdgyw"
      },
      "source": [
        "# Model for accepted inquiries (contact me only)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2qeorejJdtTi"
      },
      "source": [
        "## Split training and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfYaby3Nv9PJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drop_columns = []\n",
        "\n",
        "for c in accepted_inquiries.columns:\n",
        "  if 'contact_me' in c:\n",
        "    drop_columns.append(c)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "13442a46-82ea-48e2-8152-ac093601dbe9",
        "id": "32xDik61dvI3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "accepted_inquiries = accepted_inquiries.drop(drop_columns, axis = 1)\n",
        "accepted_inquiries = accepted_inquiries.drop(['reply_t', 'channel'], axis = 1)\n",
        "accepted_inquiries.info()"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 5169 entries, 3 to 26390\n",
            "Columns: 115 entries, accept_t to >450_char_message*>90d_lead_time\n",
            "dtypes: float64(1), int64(114)\n",
            "memory usage: 4.6 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sExj1ymAxV0T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "b037ccf8-559d-4ada-d6ec-9ee6fad3fa87"
      },
      "source": [
        "accepted_inquiries.head(10)"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accept_t</th>\n",
              "      <th>replied</th>\n",
              "      <th>accepted</th>\n",
              "      <th>booked</th>\n",
              "      <th>1-10_interactions</th>\n",
              "      <th>11-20_interactions</th>\n",
              "      <th>21-30_interactions</th>\n",
              "      <th>&gt;30_interactions</th>\n",
              "      <th>0_reviews</th>\n",
              "      <th>1-10_reviews</th>\n",
              "      <th>11-20_reviews</th>\n",
              "      <th>21-30_reviews</th>\n",
              "      <th>&gt;30_reviews</th>\n",
              "      <th>1-30d_lead_time</th>\n",
              "      <th>31-60d_lead_time</th>\n",
              "      <th>61-90d_lead_time</th>\n",
              "      <th>&gt;90d_lead_time</th>\n",
              "      <th>1-5d_stay</th>\n",
              "      <th>6-10d_stay</th>\n",
              "      <th>11-15d_stay</th>\n",
              "      <th>&gt;15d_stay</th>\n",
              "      <th>0-150_char_message</th>\n",
              "      <th>151-300_char_message</th>\n",
              "      <th>301-450_char_message</th>\n",
              "      <th>&gt;450_char_message</th>\n",
              "      <th>1_guest</th>\n",
              "      <th>2_guests</th>\n",
              "      <th>3-4_guests</th>\n",
              "      <th>5-6_guests</th>\n",
              "      <th>&gt;6_guests</th>\n",
              "      <th>past_booker</th>\n",
              "      <th>1-10_interactions*0-150_char_message</th>\n",
              "      <th>1-10_interactions*151-300_char_message</th>\n",
              "      <th>1-10_interactions*301-450_char_message</th>\n",
              "      <th>1-10_interactions*&gt;450_char_message</th>\n",
              "      <th>11-20_interactions*0-150_char_message</th>\n",
              "      <th>11-20_interactions*151-300_char_message</th>\n",
              "      <th>11-20_interactions*301-450_char_message</th>\n",
              "      <th>11-20_interactions*&gt;450_char_message</th>\n",
              "      <th>21-30_interactions*0-150_char_message</th>\n",
              "      <th>...</th>\n",
              "      <th>&gt;30_interactions*1-5d_stay</th>\n",
              "      <th>&gt;30_interactions*6-10d_stay</th>\n",
              "      <th>&gt;30_interactions*11-15d_stay</th>\n",
              "      <th>&gt;30_interactions*&gt;15d_stay</th>\n",
              "      <th>past_booker*1-10_interactions</th>\n",
              "      <th>past_booker*11-20_interactions</th>\n",
              "      <th>past_booker*21-30_interactions</th>\n",
              "      <th>past_booker*&gt;30_interactions</th>\n",
              "      <th>0-150_char_message*1-5d_stay</th>\n",
              "      <th>0-150_char_message*6-10d_stay</th>\n",
              "      <th>0-150_char_message*11-15d_stay</th>\n",
              "      <th>0-150_char_message*&gt;15d_stay</th>\n",
              "      <th>151-300_char_message*1-5d_stay</th>\n",
              "      <th>151-300_char_message*6-10d_stay</th>\n",
              "      <th>151-300_char_message*11-15d_stay</th>\n",
              "      <th>151-300_char_message*&gt;15d_stay</th>\n",
              "      <th>301-450_char_message*1-5d_stay</th>\n",
              "      <th>301-450_char_message*6-10d_stay</th>\n",
              "      <th>301-450_char_message*11-15d_stay</th>\n",
              "      <th>301-450_char_message*&gt;15d_stay</th>\n",
              "      <th>&gt;450_char_message*1-5d_stay</th>\n",
              "      <th>&gt;450_char_message*6-10d_stay</th>\n",
              "      <th>&gt;450_char_message*11-15d_stay</th>\n",
              "      <th>&gt;450_char_message*&gt;15d_stay</th>\n",
              "      <th>0-150_char_message*1-30d_lead_time</th>\n",
              "      <th>0-150_char_message*31-60d_lead_time</th>\n",
              "      <th>0-150_char_message*61-90d_lead_time</th>\n",
              "      <th>0-150_char_message*&gt;90d_lead_time</th>\n",
              "      <th>151-300_char_message*1-30d_lead_time</th>\n",
              "      <th>151-300_char_message*31-60d_lead_time</th>\n",
              "      <th>151-300_char_message*61-90d_lead_time</th>\n",
              "      <th>151-300_char_message*&gt;90d_lead_time</th>\n",
              "      <th>301-450_char_message*1-30d_lead_time</th>\n",
              "      <th>301-450_char_message*31-60d_lead_time</th>\n",
              "      <th>301-450_char_message*61-90d_lead_time</th>\n",
              "      <th>301-450_char_message*&gt;90d_lead_time</th>\n",
              "      <th>&gt;450_char_message*1-30d_lead_time</th>\n",
              "      <th>&gt;450_char_message*31-60d_lead_time</th>\n",
              "      <th>&gt;450_char_message*61-90d_lead_time</th>\n",
              "      <th>&gt;450_char_message*&gt;90d_lead_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.100</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.664</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.196</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>-0.100</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>-0.100</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>-0.100</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>-0.100</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>0.003</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>-0.100</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>-0.100</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows  115 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    accept_t  ...  >450_char_message*>90d_lead_time\n",
              "3     -0.100  ...                                 0\n",
              "6      0.664  ...                                 0\n",
              "33     0.196  ...                                 0\n",
              "45    -0.100  ...                                 0\n",
              "50    -0.100  ...                                 0\n",
              "58    -0.100  ...                                 0\n",
              "62    -0.100  ...                                 0\n",
              "63     0.003  ...                                 1\n",
              "68    -0.100  ...                                 0\n",
              "75    -0.100  ...                                 0\n",
              "\n",
              "[10 rows x 115 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J5NT9sSYdxgz",
        "colab": {}
      },
      "source": [
        "# The 15% test data will kept aside, they won't be seen by the models until final test/comparison.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "model_train, model_test = train_test_split(accepted_inquiries, test_size=0.15, random_state = 3)\n",
        "model_train_x = model_train.drop(['replied', 'accepted', 'booked'], axis = 1)\n",
        "model_test_x = model_test.drop(['replied', 'accepted', 'booked'], axis = 1)\n",
        "model_train_y = model_train['booked']\n",
        "model_test_y = model_test['booked']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N_eBxUy3dzO3"
      },
      "source": [
        "## Train model and find optimal hypermarameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o6d86dZ3d0st",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# helper function for printing out grid search results \n",
        "def print_grid_search_metrics(gs):\n",
        "    print (\"Best score: %0.3f\" % gs.best_score_)\n",
        "    print (\"Best parameters set:\")\n",
        "    best_parameters = gs.best_params_\n",
        "    for param_name in sorted(parameters.keys()):\n",
        "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5efa8e56-48a3-405e-92eb-0008f98d847a",
        "id": "5yzm6X6sd2AJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#from sklearn.ensemble import RandomForestClassifier\n",
        "#from sklearn.neighbors import KNeighborsClassifier \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Logistic Regression\n",
        "classifier_logistic = LogisticRegression()\n",
        "\n",
        "# Possible hyperparamter options for Logistic Regression Regularization\n",
        "# Penalty is choosed from L1 or L2\n",
        "# C is the lambda value(weight) for L1 and L2\n",
        "\n",
        "# ('l1', 1) ('l1', 5), ('l1', 10) ('l2', 1) ('l2', 5), ('l2', 10)\n",
        "parameters = {\n",
        "    'penalty':('l1', 'l2'), \n",
        "    'C':(1, 5, 10)\n",
        "}\n",
        "Grid_LR = GridSearchCV(LogisticRegression(),parameters, cv=5)\n",
        "Grid_LR.fit(model_train_x, model_train_y)"
      ],
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=100, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=None, solver='lbfgs',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': (1, 5, 10), 'penalty': ('l1', 'l2')},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1655cf33-2009-4b4f-c3c7-727d2d073e43",
        "id": "U-TpO6tkd8NU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# the best hyperparameter combination\n",
        "print_grid_search_metrics(Grid_LR)\n"
      ],
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best score: 0.885\n",
            "Best parameters set:\n",
            "\tC: 5\n",
            "\tpenalty: 'l2'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TUuEy_zXd-ZJ",
        "colab": {}
      },
      "source": [
        "# best model\n",
        "best_LR_model = Grid_LR.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TzXo83NJeCku"
      },
      "source": [
        "## Model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhd8nPjvjyZn",
        "colab_type": "text"
      },
      "source": [
        "### Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D9C2GFR6d_jh",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "# calculate accuracy, precision and recall, [[tn, fp],[]]\n",
        "def cal_evaluation(classifier, cm):\n",
        "    tn = cm[0][0]\n",
        "    fp = cm[0][1]\n",
        "    fn = cm[1][0]\n",
        "    tp = cm[1][1]\n",
        "    accuracy  = (tp + tn) / (tp + fp + fn + tn + 0.0)\n",
        "    precision = tp / (tp + fp + 0.0)\n",
        "    recall = tp / (tp + fn + 0.0)\n",
        "    print (classifier)\n",
        "    print (\"Accuracy is: %0.3f\" % accuracy)\n",
        "    print (\"precision is: %0.3f\" % precision)\n",
        "    print (\"recall is: %0.3f\" % recall)\n",
        "\n",
        "# print out confusion matrices\n",
        "def draw_confusion_matrices(confusion_matricies):\n",
        "    class_names = ['Not','Book']\n",
        "    for cm in confusion_matrices:\n",
        "        classifier, cm = cm[0], cm[1]\n",
        "        cal_evaluation(classifier, cm)\n",
        "        fig = plt.figure()\n",
        "        ax = fig.add_subplot(111)\n",
        "        cax = ax.matshow(cm, interpolation='nearest',cmap=plt.get_cmap('Reds'))\n",
        "        plt.title('Confusion matrix for %s' % classifier)\n",
        "        fig.colorbar(cax)\n",
        "        ax.set_xticklabels([''] + class_names)\n",
        "        ax.set_yticklabels([''] + class_names)\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('True')\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "efa38e36-ae7b-492b-bf0d-efc628b5a3a1",
        "id": "vgq9W_mieEGF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "confusion_matrix(model_test_y, best_LR_model.predict(model_test_x))"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[601,  49],\n",
              "       [ 60,  66]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f50f50fc-a2bd-4227-cc08-9a258f8f82e9",
        "id": "0lKK0q8YeGPV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# Confusion matrix, accuracy, precison and recall for random forest and logistic regression\n",
        "confusion_matrices = [\n",
        "    (\"Logistic Regression\", confusion_matrix(model_test_y, best_LR_model.predict(model_test_x))),\n",
        "    #(\"Logistic Regression\", confusion_matrix(yc_test,best_LR_model.predict(Xc_test))),\n",
        "]\n",
        "\n",
        "draw_confusion_matrices(confusion_matrices)"
      ],
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic Regression\n",
            "Accuracy is: 0.860\n",
            "precision is: 0.574\n",
            "recall is: 0.524\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T3LlJRhJj5pF"
      },
      "source": [
        "### ROC & AUC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UypvQMVBi0OY",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn import metrics\n",
        "\n",
        "# Use predict_proba to get the probability results of Logistic Regression\n",
        "y_pred_lr = best_LR_model.predict_proba(model_test_x)[:, 1]\n",
        "fpr_lr, tpr_lr, _ = roc_curve(model_test_y, y_pred_lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KZSrN-1Mi0Ok",
        "outputId": "91390452-7367-44cc-821e-e7749cca691f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# ROC Curve\n",
        "plt.figure(1)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr_lr, tpr_lr, label='LR')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve - LR Model')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LHAyxishi0On",
        "outputId": "c05e9ade-5187-41b2-9842-ff8ef189b41b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# AUC score\n",
        "metrics.auc(fpr_lr,tpr_lr)"
      ],
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8575152625152626"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3uXGGpFnZUx",
        "colab_type": "text"
      },
      "source": [
        "## Feature selection "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "scrolled": true,
        "id": "hxgXgl5RBwi4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "52e2fbcd-0556-4496-f4f1-e0ef349c8edc"
      },
      "source": [
        "# Store the coef for feature selection\n",
        "res = pd.DataFrame(columns=['Feature', 'Coef'])\n",
        "\n",
        "for k,v in sorted(zip(map(lambda x: round(x, 4), best_LR_model.fit(model_train_x, model_train_y).coef_[0]), \\\n",
        "                      model_train_x.columns), key=lambda k_v:(-abs(k_v[0]),k_v[1])):\n",
        "    print (v + \": \" + str(k))\n",
        "    res = res.append({'Feature': v, 'Coef': k}, ignore_index=True)\n"
      ],
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1-10_interactions: -1.8233\n",
            ">30_interactions*11-15d_stay: 1.2178\n",
            ">30_interactions: 1.1587\n",
            ">30_interactions*>90d_lead_time: 0.7535\n",
            "1-10_interactions*11-15d_stay: -0.7371\n",
            ">30_interactions*>450_char_message: 0.7042\n",
            ">30_interactions*151-300_char_message: 0.6729\n",
            "21-30_interactions: 0.6436\n",
            "1-10_interactions*>90d_lead_time: -0.618\n",
            "21-30_interactions*301-450_char_message: 0.5888\n",
            "1-10_interactions*6-10d_stay: -0.5517\n",
            "past_booker: 0.5403\n",
            ">15d_stay: -0.5387\n",
            "1-10_interactions*301-450_char_message: -0.538\n",
            "1-10_interactions*61-90d_lead_time: -0.5026\n",
            "1-10_interactions*151-300_char_message: -0.4812\n",
            "11-20_interactions*>15d_stay: -0.4756\n",
            "21-30_interactions*0-150_char_message: 0.468\n",
            "21-30_interactions*1-30d_lead_time: 0.4604\n",
            "1-10_interactions*>15d_stay: -0.4481\n",
            "21-30_interactions*>450_char_message: -0.4274\n",
            "0-150_char_message*61-90d_lead_time: -0.4223\n",
            "1-10_interactions*0-150_char_message: -0.4172\n",
            "301-450_char_message*61-90d_lead_time: 0.4037\n",
            "1-10_interactions*1-30d_lead_time: -0.4022\n",
            "0_reviews: -0.4003\n",
            "11-20_interactions*1-5d_stay: 0.3902\n",
            "1-10_interactions*>450_char_message: -0.3868\n",
            "21-30_interactions*>15d_stay: 0.3821\n",
            "0-150_char_message: -0.3781\n",
            ">6_guests: -0.3777\n",
            "11-20_interactions*6-10d_stay: 0.3695\n",
            "151-300_char_message*>15d_stay: -0.3669\n",
            "21-30_interactions*6-10d_stay: 0.351\n",
            "11-20_interactions*>450_char_message: 0.3213\n",
            "past_booker*1-10_interactions: 0.3129\n",
            "1-10_interactions*31-60d_lead_time: -0.3005\n",
            ">30_interactions*61-90d_lead_time: 0.2983\n",
            "11-20_interactions*11-15d_stay: -0.2643\n",
            ">30_interactions*0-150_char_message: -0.2631\n",
            "151-300_char_message*>90d_lead_time: 0.2589\n",
            "151-300_char_message*11-15d_stay: 0.2526\n",
            "151-300_char_message*1-30d_lead_time: -0.2425\n",
            "past_booker*>30_interactions: 0.2285\n",
            "11-20_interactions*61-90d_lead_time: 0.226\n",
            ">450_char_message*31-60d_lead_time: 0.2237\n",
            "6-10d_stay: 0.2152\n",
            ">450_char_message: 0.2113\n",
            "1-5d_stay: 0.2083\n",
            "2_guests: 0.2058\n",
            "0-150_char_message*1-5d_stay: -0.2055\n",
            "301-450_char_message*>90d_lead_time: -0.2043\n",
            "301-450_char_message*6-10d_stay: 0.1999\n",
            "11-20_interactions*151-300_char_message: -0.182\n",
            "3-4_guests: 0.1803\n",
            "21-30_interactions*31-60d_lead_time: 0.1659\n",
            "11-20_interactions*0-150_char_message: -0.1658\n",
            "301-450_char_message*>15d_stay: -0.1621\n",
            ">450_char_message*1-30d_lead_time: 0.1537\n",
            "301-450_char_message*1-5d_stay: 0.1522\n",
            "301-450_char_message: 0.1416\n",
            "11-20_interactions*1-30d_lead_time: -0.1396\n",
            ">30_reviews: 0.136\n",
            "301-450_char_message*31-60d_lead_time: -0.1343\n",
            "151-300_char_message*1-5d_stay: 0.1315\n",
            ">450_char_message*1-5d_stay: 0.1301\n",
            ">30_interactions*1-30d_lead_time: 0.1299\n",
            "0-150_char_message*>15d_stay: -0.1267\n",
            "11-20_interactions*>90d_lead_time: -0.1225\n",
            "5-6_guests: -0.1215\n",
            ">450_char_message*11-15d_stay: -0.1203\n",
            ">450_char_message*>15d_stay: 0.1171\n",
            "11-15d_stay: 0.1139\n",
            "past_booker*21-30_interactions: -0.1139\n",
            "past_booker*11-20_interactions: 0.1128\n",
            "1_guest: 0.1118\n",
            ">30_interactions*1-5d_stay: -0.1085\n",
            "151-300_char_message*61-90d_lead_time: 0.1072\n",
            "21-30_interactions*11-15d_stay: -0.1024\n",
            "31-60d_lead_time: -0.1018\n",
            "151-300_char_message*31-60d_lead_time: -0.0996\n",
            "21-30_reviews: 0.0969\n",
            "0-150_char_message*31-60d_lead_time: -0.0917\n",
            "1-10_reviews: 0.0884\n",
            "1-10_interactions*1-5d_stay: -0.0864\n",
            "accept_t: 0.0864\n",
            ">450_char_message*>90d_lead_time: -0.0853\n",
            ">450_char_message*6-10d_stay: 0.0844\n",
            ">450_char_message*61-90d_lead_time: -0.0809\n",
            "11-20_reviews: 0.0777\n",
            "301-450_char_message*1-30d_lead_time: 0.0764\n",
            "0-150_char_message*6-10d_stay: -0.0759\n",
            "0-150_char_message*>90d_lead_time: 0.0749\n",
            "0-150_char_message*1-30d_lead_time: 0.061\n",
            "11-20_interactions*31-60d_lead_time: 0.0557\n",
            "1-30d_lead_time: 0.0485\n",
            "301-450_char_message*11-15d_stay: -0.0484\n",
            ">30_interactions*6-10d_stay: 0.0464\n",
            "11-20_interactions*301-450_char_message: 0.0462\n",
            ">30_interactions*301-450_char_message: 0.0446\n",
            ">90d_lead_time: 0.0443\n",
            "21-30_interactions*>90d_lead_time: 0.0313\n",
            "0-150_char_message*11-15d_stay: 0.0299\n",
            "151-300_char_message: 0.024\n",
            ">30_interactions*31-60d_lead_time: -0.023\n",
            "11-20_interactions: 0.0197\n",
            "21-30_interactions*151-300_char_message: 0.0142\n",
            "21-30_interactions*61-90d_lead_time: -0.014\n",
            "21-30_interactions*1-5d_stay: 0.013\n",
            "61-90d_lead_time: 0.0077\n",
            "151-300_char_message*6-10d_stay: 0.0067\n",
            ">30_interactions*>15d_stay: 0.0029\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drGzlfJ3B9Me",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "472c7593-5c60-4c3e-ac81-bca2467475b6"
      },
      "source": [
        "res"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature</th>\n",
              "      <th>Coef</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1-10_interactions</td>\n",
              "      <td>-1.658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&gt;30_interactions</td>\n",
              "      <td>0.812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>past_booker</td>\n",
              "      <td>0.652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1-10_interactions*6-10d_stay</td>\n",
              "      <td>-0.608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1-10_interactions*&gt;90d_lead_time</td>\n",
              "      <td>-0.594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>21-30_reviews</td>\n",
              "      <td>0.007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>11-20_interactions*&gt;90d_lead_time</td>\n",
              "      <td>0.006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>1-10_reviews</td>\n",
              "      <td>-0.006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>1-30d_lead_time</td>\n",
              "      <td>-0.005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>accept_t</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>112 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                               Feature   Coef\n",
              "0                    1-10_interactions -1.658\n",
              "1                     >30_interactions  0.812\n",
              "2                          past_booker  0.652\n",
              "3         1-10_interactions*6-10d_stay -0.608\n",
              "4     1-10_interactions*>90d_lead_time -0.594\n",
              "..                                 ...    ...\n",
              "107                      21-30_reviews  0.007\n",
              "108  11-20_interactions*>90d_lead_time  0.006\n",
              "109                       1-10_reviews -0.006\n",
              "110                    1-30d_lead_time -0.005\n",
              "111                           accept_t  0.000\n",
              "\n",
              "[112 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5LN9gU4FB0sF",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "res.to_csv('mod3_res.csv')\n",
        "files.download('mod3_res.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}